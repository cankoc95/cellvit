{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from datetime import date\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import gc\n",
    "import wandb\n",
    "import uuid\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torch.distributed as dist\n",
    "# import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "# import torchvision.models as models\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "  os.environ['MASTER_ADDR'] = 'localhost'\n",
    "  os.environ['MASTER_PORT'] = '12355'\n",
    "  dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU=0\n",
    "SEED=1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU(s) available: 1\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Print num GPUs available\n",
    "print(f\"GPU(s) available: {torch.cuda.device_count()}\") \n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "  ARCH = 'maxvit_small_224'\n",
    "  START_EPOCH = 0\n",
    "  EPOCHS = 20\n",
    "  LR = 0.1\n",
    "  MOMENTUM = 0.9\n",
    "  WEIGHT_DECAY = 1e-4\n",
    "  ADAM_EPSILON = 1e-7\n",
    "  PRINT_FREQ = 50\n",
    "  TRAIN_BATCH = 64\n",
    "  VAL_BATCH = 64\n",
    "  WORKERS = 2\n",
    "  DATADIR = \"/data/home/ec2-user/broad/training_images/BBBC037/\"\n",
    "  TRAINDIR = DATADIR+\"train\"\n",
    "  VALDIR = DATADIR+\"val\"\n",
    "  TESTDIR = DATADIR+\"test\"\n",
    "\n",
    "  PRETRAINED = False\n",
    "  IMAGE_SIZE = 224\n",
    "  IN_CHANS = 5\n",
    "  NUM_CLASSES = 47\n",
    "\n",
    "  RANDOM_SEED = 42\n",
    "\n",
    "  OUTPUT_DIR = '/home/ubuntu' + '/saved_models/' + str(date.today())\n",
    "  CHECKPOINT_LAST = OUTPUT_DIR + '/' + ARCH + '/checkpoint-last'\n",
    "  CHECKPOINT_BEST = OUTPUT_DIR + '/' + ARCH + '/checkpoint-best'\n",
    "\n",
    "  WANDB_NOTEBOOK_NAME = str(date.today()) + '_' + ARCH + '_cjdonahoe'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:50dc0dc285634ee89f7621acf2ba692c) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">50dc0dc285634ee89f7621acf2ba692c</strong> at: <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/50dc0dc285634ee89f7621acf2ba692c' target=\"_blank\">https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/50dc0dc285634ee89f7621acf2ba692c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/tmpx1fjudly/wandb/run-20230325_212017-50dc0dc285634ee89f7621acf2ba692c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:50dc0dc285634ee89f7621acf2ba692c). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb1174b25204a40b59a9e795b760b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668506549982944, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/tmpxdpr467k/wandb/run-20230325_212032-d89a08b5af0548c19d9dd646115912f4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/d89a08b5af0548c19d9dd646115912f4' target=\"_blank\">d89a08b5af0548c19d9dd646115912f4</a></strong> to <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit' target=\"_blank\">https://wandb.ai/cellvit/cjdonahoe--cellvit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/d89a08b5af0548c19d9dd646115912f4' target=\"_blank\">https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/d89a08b5af0548c19d9dd646115912f4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY']='e2b77d7240d4c1ceee8264dbfbea27d2f30d5331'\n",
    "\n",
    "class WandBLogger(object):\n",
    "    def __init__(self, variant, project, prefix=''):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "        variant: dictionary of hyperparameters\n",
    "        project: name of project\n",
    "      \"\"\"\n",
    "      log_dir = tempfile.mkdtemp()\n",
    "      if prefix != '':\n",
    "          project = '{}--{}'.format(prefix, project)\n",
    "\n",
    "      wandb.init(\n",
    "          config=variant,\n",
    "          project=project,\n",
    "          dir=log_dir,\n",
    "          id=uuid.uuid4().hex,\n",
    "      )\n",
    "\n",
    "    def log(self, *args, **kwargs):\n",
    "      wandb.log(*args, **kwargs)\n",
    "\n",
    "wblogger = WandBLogger(\n",
    "    variant={\n",
    "      'initial_learning_rate': CFG.LR,\n",
    "      'adam_epsilon': CFG.ADAM_EPSILON,\n",
    "      'num_epochs': CFG.EPOCHS,\n",
    "      'batch_size': CFG.TRAIN_BATCH,\n",
    "      'weight_decay': CFG.WEIGHT_DECAY,\n",
    "      'architecture': CFG.ARCH,\n",
    "    },\n",
    "    project=f'cellvit',\n",
    "    prefix='cjdonahoe'\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(dataset):\n",
    "    ''' Get class weights for a dataset\n",
    "    Args:\n",
    "        dataset: torch.utils.data.Dataset\n",
    "    Returns:\n",
    "        class_weights: torch.FloatTensor\n",
    "    '''\n",
    "    \n",
    "    class_counts = Counter(dataset.targets)\n",
    "    total_count = len(dataset.targets)\n",
    "    class_weights = list({class_id: class_counts/total_count for class_id, class_counts in class_counts.items()}.values())\n",
    "    class_weights = torch.FloatTensor(class_weights).cuda()\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitTensorToFiveChannels(object):\n",
    "    \"\"\"Convert images in Pytorch Dataset to Tensors with one channel\n",
    "    for each discrete fluerecent image in a Cell Painting sample.\"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # select the first channel since the image is grayscale\n",
    "        img = img[0,:,:]\n",
    "        # split the image into the 6 channels and remove the last channel\n",
    "        img = torch.tensor_split(img,6,dim=1)[:-1]\n",
    "        # concatenate the 5 channels into a single tensor\n",
    "        img = torch.stack(img, dim=0)\n",
    "        return img\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxVitClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxVitClassifier(nn.Module):\n",
    "    def __init__(self, checkpoint=None):\n",
    "        super().__init__()\n",
    "        self.model_name = CFG.ARCH\n",
    "        self.model = timm.create_model(\n",
    "            CFG.ARCH,\n",
    "            in_chans=CFG.IN_CHANS,\n",
    "            pretrained=CFG.PRETRAINED, \n",
    "            num_classes=CFG.NUM_CLASSES)\n",
    "        # n_features = self.model.head.in_features\n",
    "        # self.model.head = nn.Linear(n_features, num_classes)\n",
    "        # self.model.fc = nn.Linear(n_features, num_classes)\n",
    "        if checkpoint:\n",
    "          self.model.load_state_dict(torch.load(checkpoint), strict=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def freeze(self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in tqdm(enumerate(train_loader)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # move data to GPU\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            _, preds = torch.max(output, 1)\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        # wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "\n",
    "        if i % CFG.PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "    \n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\"Training:\", epoch_loss, epoch_acc))\n",
    "\n",
    "    wblogdict[f'{\"train\"}/loss'] = np.round(epoch_loss, 4)\n",
    "    wblogdict[f'{\"train\"}/acc'] = np.round(epoch_acc.cpu(), 3)\n",
    "\n",
    "    wblogdict['train/learning_rate'] = CFG.learning_rate\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Validation: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in tqdm(enumerate(val_loader)):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % CFG.PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "    \n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\"Validation\", epoch_loss, epoch_acc))\n",
    "\n",
    "    wblogdict[f'{\"val\"}/loss'] = np.round(epoch_loss, 4)\n",
    "    wblogdict[f'{\"val\"}/acc'] = np.round(epoch_acc.cpu(), 3)\n",
    "\n",
    "    # wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    return top1.avg, top5.avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations, Datasets, & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(CFG.IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    SplitTensorToFiveChannels(),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(CFG.IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    SplitTensorToFiveChannels(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    CFG.TRAINDIR, transform=transform_train)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    CFG.VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=CFG.TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=CFG.WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=CFG.VAL_BATCH, shuffle=False,\n",
    "        num_workers=CFG.WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525539683/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = MaxVitClassifier()\n",
    "model = model.cuda(GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "# get the class weights from the validation set\n",
    "criterion = nn.CrossEntropyLoss(weight=get_class_weights(val_dataset)).cuda(GPU)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "  model.parameters(), \n",
    "  lr=CFG.LR, \n",
    "  # momentum=MOMENTUM, \n",
    "  weight_decay=CFG.WEIGHT_DECAY\n",
    "  )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2809]\tTime  3.187 ( 3.187)\tData  0.654 ( 0.654)\tLoss 4.8018e+00 (4.8018e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   6.25 (  6.25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:56,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  50/2809]\tTime  1.058 ( 1.100)\tData  0.001 ( 0.014)\tLoss nan (nan)\tAcc@1   0.00 (  2.14)\tAcc@5   1.56 (  6.59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [01:48,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 100/2809]\tTime  1.058 ( 1.080)\tData  0.002 ( 0.008)\tLoss nan (nan)\tAcc@1   0.00 (  1.58)\tAcc@5   3.12 (  5.86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [02:41,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 150/2809]\tTime  1.055 ( 1.072)\tData  0.001 ( 0.006)\tLoss nan (nan)\tAcc@1   1.56 (  1.40)\tAcc@5   3.12 (  5.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [03:34,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 200/2809]\tTime  1.060 ( 1.069)\tData  0.001 ( 0.005)\tLoss nan (nan)\tAcc@1   0.00 (  1.27)\tAcc@5   7.81 (  5.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251it [04:27,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 250/2809]\tTime  1.060 ( 1.067)\tData  0.001 ( 0.004)\tLoss nan (nan)\tAcc@1   1.56 (  1.26)\tAcc@5   6.25 (  5.61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [05:20,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 300/2809]\tTime  1.060 ( 1.066)\tData  0.001 ( 0.003)\tLoss nan (nan)\tAcc@1   0.00 (  1.23)\tAcc@5   9.38 (  5.72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "351it [06:13,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 350/2809]\tTime  1.059 ( 1.065)\tData  0.001 ( 0.003)\tLoss nan (nan)\tAcc@1   3.12 (  1.20)\tAcc@5   6.25 (  5.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [07:06,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 400/2809]\tTime  1.060 ( 1.064)\tData  0.001 ( 0.003)\tLoss nan (nan)\tAcc@1   0.00 (  1.15)\tAcc@5   6.25 (  5.65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "451it [07:59,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 450/2809]\tTime  1.059 ( 1.064)\tData  0.001 ( 0.003)\tLoss nan (nan)\tAcc@1   0.00 (  1.08)\tAcc@5   6.25 (  5.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [08:52,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 500/2809]\tTime  1.059 ( 1.063)\tData  0.002 ( 0.003)\tLoss nan (nan)\tAcc@1   0.00 (  1.06)\tAcc@5   7.81 (  5.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "551it [09:45,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 550/2809]\tTime  1.060 ( 1.063)\tData  0.001 ( 0.003)\tLoss nan (nan)\tAcc@1   1.56 (  1.08)\tAcc@5   4.69 (  5.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [10:38,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 600/2809]\tTime  1.059 ( 1.063)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   0.00 (  1.08)\tAcc@5   3.12 (  5.52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [11:31,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 650/2809]\tTime  1.059 ( 1.062)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   0.00 (  1.07)\tAcc@5   6.25 (  5.53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [12:24,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 700/2809]\tTime  1.058 ( 1.062)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   0.00 (  1.06)\tAcc@5   6.25 (  5.50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "751it [13:17,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 750/2809]\tTime  1.060 ( 1.062)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   0.00 (  1.04)\tAcc@5   9.38 (  5.46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [14:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 800/2809]\tTime  1.060 ( 1.062)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   1.56 (  1.04)\tAcc@5   7.81 (  5.48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "851it [15:03,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 850/2809]\tTime  1.058 ( 1.062)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   1.56 (  1.05)\tAcc@5   1.56 (  5.45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [15:56,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 900/2809]\tTime  1.058 ( 1.062)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   1.56 (  1.06)\tAcc@5   6.25 (  5.41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "929it [16:26,  1.06s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(CFG.START_EPOCH, CFG.EPOCHS):\n",
    "    print('Epoch {}/{}'.format(epoch, CFG.EPOCHS - 1))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    wblogdict = {}\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1, acc5 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': CFG.ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'acc5': acc5,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "\n",
    "    wblogger.log(wblogdict, step=epoch)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()[0]))\n",
    "    # wandb.log({'lr': scheduler.get_last_lr()[0]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-painting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
