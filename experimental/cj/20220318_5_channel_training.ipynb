{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "# import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy \n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import uuid\n",
    "import tempfile\n",
    "from datetime import date\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU(s) available: 1\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Print num GPUs available\n",
    "print(f\"GPU(s) available: {torch.cuda.device_count()}\") \n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 47 47\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(next(os.walk(\"/home/ubuntu/data/bbbc037\"+\"/train\"))[1]),\n",
    "    len(next(os.walk(\"/home/ubuntu/data/bbbc037\"+\"/val\"))[1]),\n",
    "    len(next(os.walk(\"/home/ubuntu/data/bbbc037\"+\"/test\"))[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "  # Set up data directories\n",
    "  data_dir=\"/home/ubuntu/data/bbbc037\"\n",
    "  train_dir=data_dir+\"/train\"\n",
    "  val_dir=data_dir+\"/val\"\n",
    "  test_dir=data_dir+\"/test\"\n",
    "  debug = False\n",
    "  n_gpu = 1\n",
    "  # device = \"cpu\" # ['cpu', 'mps']\n",
    "  img_size = 224\n",
    "  ### total # of classes in this dataset\n",
    "  num_classes = 47\n",
    "  ### model\n",
    "  model_name = 'maxvit_small_224'\n",
    "  checkpoint = 'maxvit_small_224'\n",
    "  pretrained = False\n",
    "  batch_size = 32\n",
    "  num_epochs = 10\n",
    "  in_chans = 5\n",
    "\n",
    "  ### set only one to True\n",
    "  save_best_loss = False\n",
    "  save_best_accuracy = True\n",
    "  adam_epsilon = 1e-6\n",
    "  initial_lr = 0.1\n",
    "\n",
    "  verbose = True\n",
    "\n",
    "  ### train and validation DataLoaders\n",
    "  num_workers = 8\n",
    "\n",
    "  random_seed = 42\n",
    "\n",
    "  output_dir = '/home/ubuntu' + '/saved_models_cj/' + str(date.today())\n",
    "  checkpoint_last = output_dir + '/' + model_name + '/checkpoint-last'\n",
    "  checkpoint_best = output_dir + '/' + model_name + '/checkpoint-best'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcjdonahoe\u001b[0m (\u001b[33mcellvit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/tmp_s9ikry5/wandb/run-20230320_003215-ba3def4b65d54393b86e39ea99593d02</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/ba3def4b65d54393b86e39ea99593d02' target=\"_blank\">ba3def4b65d54393b86e39ea99593d02</a></strong> to <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit' target=\"_blank\">https://wandb.ai/cellvit/cjdonahoe--cellvit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/ba3def4b65d54393b86e39ea99593d02' target=\"_blank\">https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/ba3def4b65d54393b86e39ea99593d02</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY']='e2b77d7240d4c1ceee8264dbfbea27d2f30d5331'\n",
    "\n",
    "class WandBLogger(object):\n",
    "    def __init__(self, variant, project, prefix=''):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "        variant: dictionary of hyperparameters\n",
    "        project: name of project\n",
    "      \"\"\"\n",
    "      log_dir = tempfile.mkdtemp()\n",
    "      if prefix != '':\n",
    "          project = '{}--{}'.format(prefix, project)\n",
    "\n",
    "      wandb.init(\n",
    "          config=variant,\n",
    "          project=project,\n",
    "          dir=log_dir,\n",
    "          id=uuid.uuid4().hex,\n",
    "      )\n",
    "\n",
    "    def log(self, *args, **kwargs):\n",
    "      wandb.log(*args, **kwargs)\n",
    "\n",
    "wblogger = WandBLogger(\n",
    "    variant={\n",
    "      'initial_learning_rate': CFG.initial_lr,\n",
    "      'adam_epsilon': CFG.adam_epsilon,\n",
    "      'num_epochs': CFG.num_epochs,\n",
    "      'batch_size': CFG.batch_size\n",
    "    },\n",
    "    project=f'cellvit',\n",
    "    prefix='cjdonahoe'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxVitClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxVitClassifier(nn.Module):\n",
    "    def __init__(self, cfg, checkpoint=None):\n",
    "        super().__init__()\n",
    "        self.model_name = cfg.model_name\n",
    "        self.model = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            in_chans=cfg.in_chans,\n",
    "            pretrained=cfg.pretrained, \n",
    "            num_classes=cfg.num_classes)\n",
    "        # n_features = self.model.head.in_features\n",
    "        # self.model.head = nn.Linear(n_features, num_classes)\n",
    "        # self.model.fc = nn.Linear(n_features, num_classes)\n",
    "        if checkpoint:\n",
    "          self.model.load_state_dict(torch.load(checkpoint), strict=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def freeze(self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitTensorToFiveChannels(object):\n",
    "    \"\"\"Convert images in Pytorch Dataset to Tensors with one channel\n",
    "    for each discrete fluerecent image in a Cell Painting sample.\"\"\"\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # select the first channel since the image is grayscale\n",
    "        img = img[0,:,:]\n",
    "        # split the image into the 6 channels and remove the last channel\n",
    "        img = torch.tensor_split(img,6,dim=1)[:-1]\n",
    "        # concatenate the 5 channels into a single tensor\n",
    "        img = torch.stack(img, dim=0)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(CFG.img_size),\n",
    "        transforms.ToTensor(),\n",
    "        SplitTensorToFiveChannels()#,\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(CFG.img_size),\n",
    "        transforms.ToTensor(),\n",
    "        SplitTensorToFiveChannels()\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(CFG.img_size),\n",
    "        transforms.ToTensor(),\n",
    "        SplitTensorToFiveChannels()\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(CFG.train_dir, data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(CFG.val_dir, data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(CFG.test_dir, data_transforms['test'])\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, pin_memory=True)\n",
    "dataloaders['val'] = DataLoader(val_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
    "dataloaders['test'] = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 179758\n",
      "Val dataset size: 51348\n",
      "Test dataset size: 25718\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Train dataset size: {len(train_dataset)}\",\n",
    "    f\"Val dataset size: {len(val_dataset)}\",\n",
    "    f\"Test dataset size: {len(test_dataset)}\",\n",
    "    sep = \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AKT1_E17K', 'AKT1_WT', 'ARAF_WT', 'ATF2_WT', 'ATF6_1-373', 'BCL2L11_WT', 'BRAF_V600E', 'BRAF_WT', 'CASP8_WT', 'CCND1_WT', 'CDC42_Q61L', 'CDC42_T17N', 'CDC42_WT', 'CDKN1A_WT', 'CEBPA_WT', 'CSNK1E_WT', 'CTNNB1_WT', 'CXXC4_WT', 'E2F1_WT', 'ELK1_WT', 'EMPTY', 'ERBB2_WT', 'GSK3B_WT', 'HRAS_G12V', 'JUN_WT', 'KRAS_G12V', 'KRAS_WT', 'MAP2K1_WT', 'MAP3K2_WT', 'MAP3K9_WT', 'MAPK1_WT', 'MYD88_WT', 'NOTCH1_ICN1', 'PIK3CA_WT', 'PPARGC1A_WT', 'PRKACA_WT', 'PRKCE_WT', 'PTEN_WT', 'RAC1_Q61L', 'RAF1_L613V', 'RAF1_WT', 'RB1_WT', 'RHOA_Q63L', 'RHOA_WT', 'SMAD4_WT', 'STK11_WT', 'XBP1_WT']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "print(class_names)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seed(cfg):\n",
    "    random.seed(cfg.random_seed)\n",
    "    np.random.seed(cfg.random_seed)\n",
    "    torch.manual_seed(cfg.random_seed)\n",
    "    if cfg.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(cfg.random_seed)\n",
    "\n",
    "def train_model(cfg, model, dataloaders, criterion, optimizer, scheduler):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    last_checkpoint_path = CFG.checkpoint_last\n",
    "    last_scheduler_path = os.path.join(last_checkpoint_path, 'scheduler.pt')\n",
    "    last_optimizer_path = os.path.join(last_checkpoint_path, 'optimizer.pt')\n",
    "    best_checkpoint_path = CFG.checkpoint_best\n",
    "    best_scheduler_path = os.path.join(best_checkpoint_path, 'scheduler.pt')\n",
    "    best_optimizer_path = os.path.join(best_checkpoint_path, 'optimizer.pt')\n",
    "\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, cfg.num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        wblogdict = {}\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.autocast(device_type='cuda'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            wblogdict[f'{phase}/loss'] = np.round(epoch_loss, 4)\n",
    "            wblogdict[f'{phase}/acc'] = np.round(epoch_acc.cpu(), 3)\n",
    "\n",
    "            if phase == \"train\":\n",
    "              wblogdict['train/learning_rate'] = CFG.learning_rate\n",
    "\n",
    "            if not os.path.exists(last_checkpoint_path):\n",
    "                os.makedirs(last_checkpoint_path)\n",
    "            \n",
    "            torch.save(model.state_dict(), last_checkpoint_path + f\"/MaxVitModel_ep{epoch_acc}.pth\")\n",
    "            torch.save(optimizer.state_dict(), last_optimizer_path)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "                if not os.path.exists(best_checkpoint_path):\n",
    "                    os.makedirs(best_checkpoint_path)\n",
    "\n",
    "                torch.save(model.state_dict(), best_checkpoint_path + f\"/MaxVitModel_ep{best_acc}.pth\")\n",
    "                torch.save(optimizer.state_dict(), best_optimizer_path)\n",
    "  \n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        wblogger.log(wblogdict)\n",
    "        print()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/mambaforge/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1673730874951/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "GPU = 0\n",
    "\n",
    "# model.cuda(GPU)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)\n",
    "\n",
    "model_ft = MaxVitClassifier(CFG)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_ft.parameters(), \n",
    "    lr=CFG.initial_lr, \n",
    "    eps=CFG.adam_epsilon)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.num_epochs, eta_min=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1253/5618 [12:19<42:54,  1.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft, hist \u001b[39m=\u001b[39m train_model(CFG, model_ft, dataloaders, criterion, optimizer, scheduler)\n",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(cfg, model, dataloaders, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39m# backward + optimize only if in training phase\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m         loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     61\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     63\u001b[0m \u001b[39m# statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft, hist = train_model(CFG, model_ft, dataloaders, criterion, optimizer, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
