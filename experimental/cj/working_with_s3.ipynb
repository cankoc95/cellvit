{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 # AWS SDK for Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata\n",
    "metadata_df = pd.read_parquet(\"/Users/cjdonahoe/github/cellvit/metadata/metadata.parquet\")\n",
    "\n",
    "print(metadata_df[['Image_Name', 'Treatment']].head(5))\n",
    "\n",
    "for index, row in metadata_df.head(5).iterrows():\n",
    "    substr_raw = row['Image_Name'][21:]\n",
    "    print(substr_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = ''\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = ''\n",
    "\n",
    "# Get environment variables\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.environ.get('AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "  's3', \n",
    "  aws_access_key_id=AWS_ACCESS_KEY_ID, \n",
    "  aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('cpg0019-moshkov-deepprofiler')\n",
    "\n",
    "# find all prefixes that start with 'broad/training_images/BBBC021/'\n",
    "def get_prefixes(bucket, prefix):\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    operation_parameters = {'Bucket': bucket, 'Prefix': prefix, 'Delimiter': '/'}\n",
    "    page_iterator = paginator.paginate(**operation_parameters)\n",
    "    prefixes = []\n",
    "    for page in page_iterator:\n",
    "        if 'CommonPrefixes' in page:\n",
    "            prefixes.extend([cp['Prefix'] for cp in page['CommonPrefixes']])\n",
    "    return prefixes\n",
    "\n",
    "for obj in bucket.objects.filter(Prefix='broad/training_images/BBBC021/'):\n",
    "    print(obj.key)\n",
    "    substr_raw = obj.key[21:]\n",
    "    print(substr_raw)\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_exists_and_not_empty(bucket:str, path:str) -> bool:\n",
    "    '''\n",
    "    Folder should exists. \n",
    "    Folder should not be empty.\n",
    "    '''\n",
    "    s3 = boto3.client('s3')\n",
    "    if not path.endswith('/'):\n",
    "        path = path+'/' \n",
    "    resp = s3.list_objects(Bucket=bucket, Prefix=path, Delimiter='/',MaxKeys=1)\n",
    "    return 'Contents' in resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folder_exists_and_not_empty('cpg0019-moshkov-deepprofiler', 'broad/training_images/BBBC037'))\n",
    "print(get_prefixes('cpg0019-moshkov-deepprofiler', 'broad/training_images/BBBC037/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prefixes = get_prefixes('cpg0019-moshkov-deepprofiler', 'broad/training_images/BBBC037/')\n",
    "print(list_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_collection_df = metadata_df[metadata_df['Collection'] == COLLECTION]\n",
    "for index, row in single_collection_df.iterrows():\n",
    "    # get the full path to each image in single_collection_df\n",
    "    src = ROOT_PATH + row['Image_Name'][22:]\n",
    "    # check if a directory for the treatment exists in S3\n",
    "    if :\n",
    "        os.makedirs(root_path + collection + \"/\" + row['Treatment'])\n",
    "\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'cpg0019-moshkov-deepprofiler'\n",
    "PREFIX = 'broad/training_images/BBBC037/'\n",
    "\n",
    "bucket = s3.Bucket('cpg0019-moshkov-deepprofiler')\n",
    "objs = list(bucket.objects.filter(Prefix=PREFIX))\n",
    "objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_folder_exists(bucket, folder):\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket)\n",
    "    objs = list(bucket.objects.filter(Prefix=folder))\n",
    "    if len(objs) > 0 and objs[0].key == folder:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_directory(bucket_name, directory_name):\n",
    "    \"\"\"Create a directory in an S3 bucket\n",
    "\n",
    "    :param bucket_name: Bucket to create directory in\n",
    "    :param directory_name: Directory to create\n",
    "    :return: True if directory was created, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the bucket\n",
    "    try:\n",
    "        response = s3_client.put_object(Bucket=bucket_name, Key=(directory_name))\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_keys(bucket, prefix=None):\n",
    "    \"\"\"Get a list of keys in an S3 bucket.\n",
    "\n",
    "    :param bucket: Name of the S3 bucket.\n",
    "    :return: List of keys in the bucket.\n",
    "    \"\"\"\n",
    "\n",
    "    keys = []\n",
    "\n",
    "    resp = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    for obj in resp['Contents']:\n",
    "        keys.append(obj['Key'])\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key_list = get_s3_keys('cpg0019-moshkov-deepprofiler', prefix='broad/training_images/BBBC037/')\n",
    "s3_key_list = set([x.split('/')[4] for x in s3_key_list])\n",
    "print(s3_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_rename_move_s3_key(bucket_name, old_key, new_key):\n",
    "    \"\"\"Copy, rename, and move an S3 key\n",
    "\n",
    "    :param bucket_name: Bucket to copy key from\n",
    "    :param old_key: Old key name\n",
    "    :param new_key: New key name\n",
    "    :return: True if key was copied, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the object\n",
    "    try:\n",
    "        copy_source = {\n",
    "            'Bucket': bucket_name,\n",
    "            'Key': old_key\n",
    "        }\n",
    "        s3_client.copy(copy_source, bucket_name, new_key)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_s3_directory('cpg0019-moshkov-deepprofiler', 'broad/training_images/BBBC037_pytorch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x = [i[-6:-1] for i in get_prefixes('cpg0019-moshkov-deepprofiler', 'broad/training_images/BBBC037_pytorch/')]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='cpg0019-moshkov-deepprofiler'\n",
    "file_prefix='broad/training_images/BBBC021/'\n",
    "\n",
    "result = s3_client.list_objects_v2(Bucket=bucket, Prefix=file_prefix)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('cpg0019-moshkov-deepprofiler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_rename_img(root_path, collection: str):\n",
    "  # get the metadata for a single collection\n",
    "  single_collection_df = metadata_df[metadata_df['Collection'] == collection]\n",
    "  # iterate through the rows of the single collection metadata\n",
    "  for index, row in single_collection_df.iterrows():\n",
    "      # get the full path to each image in single_collection_df\n",
    "      src = root_path + row['Image_Name'][22:]\n",
    "      # check if a directory for the treatment exists\n",
    "      if not os.path.exists(root_path + collection + \"/\" + row['Treatment']):\n",
    "          # if not, create the directory\n",
    "          os.makedirs(root_path + collection + \"/\" + row['Treatment'])\n",
    "      # store the new path for the image in dst\n",
    "      dst = root_path + collection + \"/\" + row['Treatment'] + \"/\" + row['Metadata_Plate'] + \"_\" + row['Metadata_Well'] + \"_\" + row['Metadata_Site'] + \"_\" + row['PathId']\n",
    "      # copy the image to the new path\n",
    "      shutil.copy(src, dst)\n",
    "  return\n",
    "\n",
    "# copy_and_rename_img('BBBC037')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_rename_img_s3(src_bucket:str, dst_bucket:str, collection:str):\n",
    "  s3 = boto3.resource('s3')\n",
    "  # get the metadata for a single collection\n",
    "  single_collection_df = metadata_df[metadata_df['Collection'] == collection]\n",
    "  file_counter = 0\n",
    "  # iterate through the rows of the single collection metadata\n",
    "  for index, row in single_collection_df.iterrows():\n",
    "      # get the full path to each image in single_collection_df\n",
    "      copy_source = {\n",
    "          'Bucket': src_bucket,\n",
    "          'Key': 'broad/training_images/' + row['Image_Name'][22:]\n",
    "      }\n",
    "      dst_key = 'broad/training_images/' + collection + \"/\" + row['Treatment'] + \"/\" + row['Metadata_Plate'] + \"_\" + row['Metadata_Well'] + \"_\" + row['Metadata_Site'] + \"_\" + row['PathId']\n",
    "      bucket = s3.Bucket(dst_bucket)\n",
    "      bucket.copy(copy_source, dst_key)\n",
    "      file_counter += 1\n",
    "      if file_counter % 5000 == 0:\n",
    "          print(f\"{file_counter} files copied\")\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_and_rename_img_s3('cpg0019-moshkov-deepprofiler', 'bbbc037-pytorch', 'BBBC037')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/Users/cjdonahoe/Documents/personal/ucb-mids/210-capstone/cellpainting-gallery/cpg0019-moshkov-deepprofiler/broad/workspace_dl/training_images/\"\n",
    "copy_and_rename_img_s3(ROOT_PATH, collection='BBBC037')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_s3_object():\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket('cpg0019-moshkov-deepprofiler')\n",
    "    for obj in bucket.objects.filter(Prefix='broad/training_images/BBBC037/'):\n",
    "        print(obj.key)\n",
    "        substr_raw = obj.key[len('broad/training_images/BBBC037/'):]\n",
    "        print(substr_raw)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_s3_object()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell-painting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
