{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rKbz-q1dYGVp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/conda/envs/pytorch/lib/python3.9/site-packages (2.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (4.63.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (2.28.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
            "Requirement already satisfied: xxhash in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: responses<0.19 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /opt/conda/envs/pytorch/lib/python3.9/site-packages (4.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (4.63.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: timm in /opt/conda/envs/pytorch/lib/python3.9/site-packages (0.8.15.dev0)\n",
            "Requirement already satisfied: torch>=1.7 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from timm) (1.13.1)\n",
            "Requirement already satisfied: torchvision in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from timm) (0.14.1)\n",
            "Requirement already satisfied: pyyaml in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from timm) (5.4.1)\n",
            "Requirement already satisfied: safetensors in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from timm) (0.3.0)\n",
            "Requirement already satisfied: huggingface-hub in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from timm) (0.13.2)\n",
            "Requirement already satisfied: typing_extensions in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (4.63.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (2.28.2)\n",
            "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (3.6.0)\n",
            "Requirement already satisfied: numpy in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: wandb in /opt/conda/envs/pytorch/lib/python3.9/site-packages (0.14.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (2.28.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (3.20.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: pathtools in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (67.6.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: setproctitle in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from wandb) (1.17.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/pytorch/lib/python3.9/site-packages (from opencv-python) (1.23.5)\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.7.0.72\n"
          ]
        }
      ],
      "source": [
        "# !pip install torch torchvision\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install --pre timm\n",
        "!pip install wandb\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tO7DjSN6YDov"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.pyplot._IonContext at 0x7ff29a7ba7f0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import timm\n",
        "import pandas as pd\n",
        "# from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "from datasets import Dataset\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "import cv2\n",
        "import wandb\n",
        "import uuid\n",
        "import tempfile\n",
        "from datetime import datetime, date\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bj-zSDkzpl7h"
      },
      "outputs": [],
      "source": [
        "CELL_PAINTING_DIR = '/home/ubuntu/src'\n",
        "CACHE_DIR = CELL_PAINTING_DIR + \"/cache\"\n",
        "BROAD_DIR = CELL_PAINTING_DIR + '/data/cpg0019-moshkov-deepprofiler/broad'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3M7YRoHJIrxK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "class_labels_to_int = {\n",
        "    'AKT1_E17K': 0,\n",
        "    'AKT1_WT': 1,\n",
        "    'BRAF_V600E': 2,\n",
        "    'BRAF_WT': 3,\n",
        "    'CDC42_Q61L': 4,\n",
        "    'CDC42_T17N': 5,\n",
        "    'CDC42_WT': 6,\n",
        "    'EMPTY': 7,\n",
        "    'KRAS_G12V': 8,\n",
        "    'KRAS_WT': 9,\n",
        "    'RAF1_L613V': 10,\n",
        "    'RAF1_WT': 11,\n",
        "    'RHOA_Q63L': 12,\n",
        "    'RHOA_WT': 13\n",
        "}\n",
        "print(len(class_labels_to_int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YVqgh9ATWVc"
      },
      "source": [
        "### Prepare train/dev dataset (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F56q2a60T1ZI"
      },
      "outputs": [],
      "source": [
        "# def add_image_paths(row, delim='../../', prefix=BROAD_DIR):\n",
        "#     _, path_suffix = row.Image_Name.split(delim)\n",
        "#     path = prefix + \"/\" + path_suffix\n",
        "#     return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "On2y_qoRKC4j"
      },
      "outputs": [],
      "source": [
        "# from data_fetcher import DataFetcher\n",
        "# c037_14k_dataset = pd.read_parquet(CACHE_DIR + \"/c037_14k_metadata.parquet\", engine=\"pyarrow\")\n",
        "# print(c037_14k_dataset.shape)\n",
        "# c037_14k_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v3kjpBM2HmHb"
      },
      "outputs": [],
      "source": [
        "# c037_14k_dataset['Path'] = c037_14k_dataset.apply(lambda x: add_image_paths(x), axis=1)\n",
        "# c037_14k_dataset['Labels'] = c037_14k_dataset[\"Treatment\"].replace(\n",
        "#           to_replace=class_labels_to_int)\n",
        "# print(c037_14k_dataset.shape)\n",
        "# c037_14k_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-vsdbxR7Hs5K"
      },
      "outputs": [],
      "source": [
        "# c037_14k_dataset_clean = DataFetcher.clean_data(c037_14k_dataset)\n",
        "# c037_14k_dataset_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M7ZeNAX0UQQV"
      },
      "outputs": [],
      "source": [
        "# DataFetcher.create_train_dev_split(c037_14k_dataset_clean, CACHE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bsmB1TG4UNsF"
      },
      "outputs": [],
      "source": [
        "# # Add channel information to each train and dev dataset\n",
        "\n",
        "# for dataset_t in [\"train\", \"dev\"]:\n",
        "#   dataset_file = CACHE_DIR + f\"/{dataset_t}/data.parquet\"\n",
        "#   dataset_df = pd.read_parquet(dataset_file, engine=\"pyarrow\")\n",
        "#   dataset_df = DataFetcher.repeat_channels(dataset_df)\n",
        "#   dataset_df = dataset_df.drop(columns=['__index_level_0__'])\n",
        "#   dataset_df.to_parquet(dataset_file, engine=\"pyarrow\")\n",
        "#   print(f\"Added channels to {dataset_file}, shape is: {dataset_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vAD6_OayJhsT"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "  data_dir = CACHE_DIR\n",
        "  debug = False\n",
        "  n_gpu = 1\n",
        "  # device = \"cpu\" # ['cpu', 'mps']\n",
        "  img_size = 224\n",
        "  ### total # of classes in this dataset\n",
        "  num_classes = len(class_labels_to_int)\n",
        "  ### model\n",
        "  model_name = 'maxvit_base_tf_224'\n",
        "  checkpoint = 'maxvit_base_tf_224'\n",
        "  pretrained=True\n",
        "  batch_size = 20\n",
        "  num_epochs = 10\n",
        "\n",
        "  ### set only one to True\n",
        "  save_best_loss = False\n",
        "  save_best_accuracy = True\n",
        "\n",
        "  optimizer = 'adamw' # [\"rmsprop\", \"adam\"]\n",
        "  learning_rate = 5e-5\n",
        "  adam_epsilon = 1e-6\n",
        "  weight_decay = 0.1 # for adamw\n",
        "  l2_penalty = 0.01 # for RMSprop\n",
        "  rms_momentum = 0 # for RMSprop\n",
        "\n",
        "  ### learning rate scheduler (LRS)\n",
        "  scheduler = 'ReduceLROnPlateau' # []\n",
        "  # scheduler = 'CosineAnnealingLR'\n",
        "  plateau_factor = 0.5\n",
        "  plateau_patience = 3\n",
        "  cosine_T_max = 4\n",
        "  cosine_eta_min = 1e-8\n",
        "  verbose = True\n",
        "\n",
        "  ### train and validation DataLoaders\n",
        "  shuffle = True\n",
        "\n",
        "  random_seed = 42\n",
        "\n",
        "  output_dir = '/dev/shm/model_checkpoints/' + str(date.today())\n",
        "  checkpoint_last = output_dir + '/' + model_name + '/checkpoint-last'\n",
        "  checkpoint_best = output_dir + '/' + model_name + '/checkpoint-best'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OCoVXjIL-lO7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcankoc\u001b[0m (\u001b[33mcellvit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/tmp/tmp9u6l80vx/wandb/run-20230319_073653-26f9fbc98f8042be8a1bf5d8b8997e93</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cellvit/c037_14k--cellvit-maxvit_base_tf_224/runs/26f9fbc98f8042be8a1bf5d8b8997e93' target=\"_blank\">26f9fbc98f8042be8a1bf5d8b8997e93</a></strong> to <a href='https://wandb.ai/cellvit/c037_14k--cellvit-maxvit_base_tf_224' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cellvit/c037_14k--cellvit-maxvit_base_tf_224' target=\"_blank\">https://wandb.ai/cellvit/c037_14k--cellvit-maxvit_base_tf_224</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cellvit/c037_14k--cellvit-maxvit_base_tf_224/runs/26f9fbc98f8042be8a1bf5d8b8997e93' target=\"_blank\">https://wandb.ai/cellvit/c037_14k--cellvit-maxvit_base_tf_224/runs/26f9fbc98f8042be8a1bf5d8b8997e93</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "os.environ['WANDB_API_KEY']='808606b1ec54e09c37c9c19ea6bb8d5b8a679987'\n",
        "\n",
        "class WandBLogger(object):\n",
        "    def __init__(self, variant, project, prefix=''):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        variant: dictionary of hyperparameters\n",
        "        project: name of project\n",
        "      \"\"\"\n",
        "      log_dir = tempfile.mkdtemp()\n",
        "      if prefix != '':\n",
        "          project = '{}--{}'.format(prefix, project)\n",
        "\n",
        "      wandb.init(\n",
        "          config=variant,\n",
        "          project=project,\n",
        "          dir=log_dir,\n",
        "          id=uuid.uuid4().hex,\n",
        "      )\n",
        "\n",
        "    def log(self, *args, **kwargs):\n",
        "      wandb.log(*args, **kwargs)\n",
        "\n",
        "wblogger = WandBLogger(\n",
        "    variant={\n",
        "      'initial_learning_rate': CFG.learning_rate,\n",
        "      'adam_epsilon': CFG.adam_epsilon,\n",
        "      'num_epochs': CFG.num_epochs,\n",
        "      'batch_size': CFG.batch_size\n",
        "    },\n",
        "    project=f'cellvit-{CFG.model_name}',\n",
        "    prefix='c037_14k'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riwos9s8Frbj"
      },
      "source": [
        "### Create a custom pytorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0Y1PVZk6X2dO"
      },
      "outputs": [],
      "source": [
        "from maxvit_dataset import MaxVitDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96QFK1BfF3Ro"
      },
      "source": [
        "### Check to see if custom Dataset is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mfvWag_GogEB"
      },
      "outputs": [],
      "source": [
        "# training_data = MaxVitDataset(CFG, \"train\")\n",
        "# dev_data = MaxVitDataset(CFG, \"dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tLuAKfJRKrGr"
      },
      "outputs": [],
      "source": [
        "# print(\"Training and dev data sizes\")\n",
        "# print(len(training_data))\n",
        "# print(len(dev_data))\n",
        "# print(\"Training and dev data at idx\")\n",
        "# print(training_data[0][0].shape)\n",
        "# print(training_data[0][0].dtype)\n",
        "# print(training_data[0][0])\n",
        "# print(training_data[0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x34kalKxKg5L"
      },
      "source": [
        "### Inspect a subset of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ytl8lilzBql2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "# 1. Take in a Dataset as well as a list of class names\n",
        "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "    \n",
        "    # 2. Adjust display if n too high\n",
        "    if n > 10:\n",
        "        n = 10\n",
        "        display_shape = False\n",
        "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "    \n",
        "    # 3. Set random seed\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 4. Get random sample indexes\n",
        "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "    # 5. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 6. Loop through samples and display random samples \n",
        "    for i, targ_sample in enumerate(random_samples_idx):\n",
        "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
        "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "        # Plot adjusted samples\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(targ_image_adjust)\n",
        "        plt.axis(\"off\")\n",
        "        title = f\"class: {targ_label}\"\n",
        "        if display_shape:\n",
        "            title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wUBCsvD0DgSj"
      },
      "outputs": [],
      "source": [
        "# display_random_images(training_data, n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Ve1GWlZ1dj"
      },
      "source": [
        "### Fine Tuning With Timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8v-t430TD61V"
      },
      "outputs": [],
      "source": [
        "class MaxVitClassifier(nn.Module):\n",
        "    def __init__(self, cfg, checkpoint=None):\n",
        "        super().__init__()\n",
        "        self.model_name = cfg.model_name\n",
        "        self.model = timm.create_model(cfg.model_name, \n",
        "                                       pretrained=cfg.pretrained, \n",
        "                                       num_classes=cfg.num_classes)\n",
        "        # n_features = self.model.head.in_features\n",
        "        # self.model.head = nn.Linear(n_features, num_classes)\n",
        "        # self.model.fc = nn.Linear(n_features, num_classes)\n",
        "        if checkpoint:\n",
        "          self.model.load_state_dict(torch.load(checkpoint), strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "    \n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in self.model.head.parameters():\n",
        "            param.requires_grad = True\n",
        "    \n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Sx2gF_qeEaga"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset sizes: {'train': 56000, 'dev': 14000}\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'dev': transforms.Compose([\n",
        "        transforms.CenterCrop(CFG.img_size),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: MaxVitDataset(CFG, split=x,\n",
        "                                   transform=data_transforms[x])\n",
        "                  for x in ['train', 'dev']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
        "                                              batch_size=CFG.batch_size,\n",
        "                                              num_workers=20,\n",
        "                                              shuffle=True)\n",
        "              for x in ['train', 'dev']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'dev']}\n",
        "# class_names = image_datasets['train'].classes\n",
        "print(f\"Dataset sizes: {dataset_sizes}\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else CFG.device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fUUKdWLEEVjf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_seed(cfg):\n",
        "    random.seed(cfg.random_seed)\n",
        "    np.random.seed(cfg.random_seed)\n",
        "    torch.manual_seed(cfg.random_seed)\n",
        "    if cfg.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(cfg.random_seed)\n",
        "\n",
        "def train_model(cfg, model, dataloaders, criterion, optimizer, scheduler):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    last_checkpoint_path = CFG.checkpoint_last\n",
        "    last_scheduler_path = os.path.join(last_checkpoint_path, 'scheduler.pt')\n",
        "    last_optimizer_path = os.path.join(last_checkpoint_path, 'optimizer.pt')\n",
        "    best_checkpoint_path = CFG.checkpoint_best\n",
        "    best_scheduler_path = os.path.join(best_checkpoint_path, 'scheduler.pt')\n",
        "    best_optimizer_path = os.path.join(best_checkpoint_path, 'optimizer.pt')\n",
        "\n",
        "    for epoch in range(cfg.num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, cfg.num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        wblogdict = {}\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'dev']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            wblogdict[f'{phase}/loss'] = np.round(epoch_loss, 4)\n",
        "            wblogdict[f'{phase}/acc'] = np.round(epoch_acc.cpu(), 4)\n",
        "\n",
        "            if phase == \"train\":\n",
        "              wblogdict['train/learning_rate'] = CFG.learning_rate\n",
        "\n",
        "            if not os.path.exists(last_checkpoint_path):\n",
        "                os.makedirs(last_checkpoint_path)\n",
        "            \n",
        "            torch.save(model.state_dict(), last_checkpoint_path + f\"/MaxVitModel_ep{epoch_acc}.pth\")\n",
        "            torch.save(optimizer.state_dict(), last_optimizer_path)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'dev' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "                if not os.path.exists(best_checkpoint_path):\n",
        "                    os.makedirs(best_checkpoint_path)\n",
        "\n",
        "                torch.save(model.state_dict(), best_checkpoint_path + f\"/MaxVitModel_ep{best_acc}.pth\")\n",
        "                torch.save(optimizer.state_dict(), best_optimizer_path)\n",
        "  \n",
        "            if phase == 'dev':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "        wblogger.log(wblogdict)\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Mu4FdLMfHKCL"
      },
      "outputs": [],
      "source": [
        "# model_ft = models.resnet18(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# # Here the size of each output sample is set to 2.\n",
        "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "set_seed(CFG)\n",
        "\n",
        "checkpoint = CELL_PAINTING_DIR + '/MaxVitModel_ep0.6236428571428572.pth'\n",
        "model_ft = MaxVitClassifier(CFG, checkpoint=checkpoint)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "# print(\"Params to learn:\")\n",
        "\n",
        "# for name,param in model_ft.named_parameters():\n",
        "#     if param.requires_grad == True:\n",
        "#             print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=5e-5, momentum=0.9)\n",
        "\n",
        "optimizer_ft = AdamW(model_ft.parameters(), lr=CFG.learning_rate, eps=CFG.adam_epsilon, weight_decay=CFG.weight_decay)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=CFG.plateau_factor, patience=CFG.plateau_patience)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-HtsnLwtLlKE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 2800/2800 [25:47<00:00,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.8306 Acc: 0.3899\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 700/700 [02:03<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dev Loss: 1.8655 Acc: 0.4016\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|███████████████▍                                                                                      | 424/2800 [03:54<21:49,  1.81it/s]"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to interrupt the Kernel. \n",
            "\u001b[1;31mKernel connection disconnected. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model_ft, hist = train_model(CFG, model_ft, dataloaders, criterion, optimizer_ft, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn2UMID6gR5G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
