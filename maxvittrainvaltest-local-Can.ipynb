{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rKbz-q1dYGVp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (1.13.1)\n",
            "Requirement already satisfied: torchvision in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (0.14.1)\n",
            "Requirement already satisfied: typing-extensions in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torchvision) (9.1.0)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torchvision) (1.22.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->torchvision) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: datasets in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (2.10.1)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (2022.3.0)\n",
            "Requirement already satisfied: xxhash in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: responses<0.19 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (0.13.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (1.22.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
            "Requirement already satisfied: multiprocess in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
            "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (4.26.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (1.22.3)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: timm in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (0.8.15.dev0)\n",
            "Requirement already satisfied: huggingface-hub in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from timm) (0.13.1)\n",
            "Requirement already satisfied: torch>=1.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from timm) (1.13.1)\n",
            "Requirement already satisfied: torchvision in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from timm) (0.14.1)\n",
            "Requirement already satisfied: safetensors in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from timm) (0.3.0)\n",
            "Requirement already satisfied: pyyaml in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from timm) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub->timm) (4.63.0)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torchvision->timm) (9.1.0)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from torchvision->timm) (1.22.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install --pre timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tO7DjSN6YDov"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.pyplot._IonContext at 0x104849a90>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import timm\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "from datasets import Dataset\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "import cv2\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bj-zSDkzpl7h"
      },
      "outputs": [],
      "source": [
        "# CACHE_DIR = \"./cache\"\n",
        "CELL_PAINTING_DIR = \"/Users/cankoc/Coursework/cellvit\"\n",
        "BROAD_DIR = \"/Users/cankoc/Coursework/cellpainting-gallery/cpg0019-moshkov-deepprofiler/broad\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qq0InJMiY7cU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "class_labels_to_int = {\n",
        "    'AKT1_E17K': 0,\n",
        "    'AKT1_WT': 1,\n",
        "    'BRAF_V600E': 2,\n",
        "    'BRAF_WT': 3,\n",
        "    'CDC42_Q61L': 4,\n",
        "    'CDC42_T17N': 5,\n",
        "    'CDC42_WT': 6,\n",
        "    'EMPTY': 7,\n",
        "    'KRAS_G12V': 8,\n",
        "    'KRAS_WT': 9,\n",
        "    'RAF1_L613V': 10,\n",
        "    'RAF1_WT': 11,\n",
        "    'RHOA_Q63L': 12,\n",
        "    'RHOA_WT': 13\n",
        "}\n",
        "print(len(class_labels_to_int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vAD6_OayJhsT"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "  data_dir = CELL_PAINTING_DIR + \"/cache\"\n",
        "  debug = False\n",
        "  n_gpu = 0\n",
        "  img_size = 224\n",
        "  ### total # of classes in this dataset\n",
        "  num_classes = len(class_labels_to_int)\n",
        "  ### model\n",
        "  model_name = 'maxvit_base_tf_224'\n",
        "  pretrained=True\n",
        "  batch_size = 64\n",
        "  num_epochs = 30\n",
        "\n",
        "  ### set only one to True\n",
        "  save_best_loss = False\n",
        "  save_best_accuracy = True\n",
        "\n",
        "  optimizer = 'adamw' # [\"rmsprop\", \"adam\"]\n",
        "  learning_rate = 5e-5\n",
        "  adam_epsilon = 1e-6\n",
        "  weight_decay = 0.1 # for adamw\n",
        "  l2_penalty = 0.01 # for RMSprop\n",
        "  rms_momentum = 0 # for RMSprop\n",
        "\n",
        "  ### learning rate scheduler (LRS)\n",
        "  scheduler = 'ReduceLROnPlateau' # []\n",
        "  # scheduler = 'CosineAnnealingLR'\n",
        "  plateau_factor = 0.5\n",
        "  plateau_patience = 3\n",
        "  cosine_T_max = 4\n",
        "  cosine_eta_min = 1e-8\n",
        "  verbose = True\n",
        "\n",
        "  ### train and validation DataLoaders\n",
        "  shuffle = True\n",
        "\n",
        "  random_seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riwos9s8Frbj"
      },
      "source": [
        "### Create a custom pytorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0Y1PVZk6X2dO"
      },
      "outputs": [],
      "source": [
        "from maxvit_dataset import MaxVitDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96QFK1BfF3Ro"
      },
      "source": [
        "### Check to see if custom Dataset is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mfvWag_GogEB"
      },
      "outputs": [],
      "source": [
        "# training_data = MaxVitDataset(CFG, \"train\")\n",
        "# dev_data = MaxVitDataset(CFG, \"dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tLuAKfJRKrGr"
      },
      "outputs": [],
      "source": [
        "# print(\"Training and dev data sizes\")\n",
        "# print(len(training_data))\n",
        "# print(len(dev_data))\n",
        "# print(\"Training and dev data at idx\")\n",
        "# print(training_data[0][0].shape)\n",
        "# print(training_data[0][0].dtype)\n",
        "# print(training_data[0][0])\n",
        "# print(training_data[0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x34kalKxKg5L"
      },
      "source": [
        "### Inspect a subset of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ytl8lilzBql2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "# 1. Take in a Dataset as well as a list of class names\n",
        "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "    \n",
        "    # 2. Adjust display if n too high\n",
        "    if n > 10:\n",
        "        n = 10\n",
        "        display_shape = False\n",
        "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "    \n",
        "    # 3. Set random seed\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 4. Get random sample indexes\n",
        "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "    # 5. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 6. Loop through samples and display random samples \n",
        "    for i, targ_sample in enumerate(random_samples_idx):\n",
        "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
        "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "        # Plot adjusted samples\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(targ_image_adjust)\n",
        "        plt.axis(\"off\")\n",
        "        title = f\"class: {targ_label}\"\n",
        "        if display_shape:\n",
        "            title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wUBCsvD0DgSj"
      },
      "outputs": [],
      "source": [
        "# display_random_images(training_data, n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Ve1GWlZ1dj"
      },
      "source": [
        "### Fine Tuning With Timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8v-t430TD61V"
      },
      "outputs": [],
      "source": [
        "class MaxVitClassifier(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(cfg.model_name, \n",
        "                                       pretrained=cfg.pretrained, \n",
        "                                       num_classes=cfg.num_classes)\n",
        "        # n_features = self.model.head.in_features\n",
        "        # self.model.head = nn.Linear(n_features, num_classes)\n",
        "        # self.model.fc = nn.Linear(n_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "    \n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in self.model.head.parameters():\n",
        "            param.requires_grad = True\n",
        "    \n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sx2gF_qeEaga"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset sizes: {'train': 56000, 'dev': 14000}\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'dev': transforms.Compose([\n",
        "        transforms.CenterCrop(CFG.img_size),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: MaxVitDataset(CFG, split=x,\n",
        "                                   transform=data_transforms[x])\n",
        "                  for x in ['train', 'dev']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
        "                                              batch_size=CFG.batch_size,\n",
        "                                              num_workers=20,\n",
        "                                              shuffle=True)\n",
        "              for x in ['train', 'dev']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'dev']}\n",
        "# class_names = image_datasets['train'].classes\n",
        "print(f\"Dataset sizes: {dataset_sizes}\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([64, 3, 224, 224])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Invalid shape (3, 224, 224) for image data",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/cankoc/Coursework/cellvit/maxvittrainvaltest-local.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cankoc/Coursework/cellvit/maxvittrainvaltest-local.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m img \u001b[39m=\u001b[39m train_features[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cankoc/Coursework/cellvit/maxvittrainvaltest-local.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m label \u001b[39m=\u001b[39m train_labels[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cankoc/Coursework/cellvit/maxvittrainvaltest-local.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39;49mimshow(img, cmap\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgray\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cankoc/Coursework/cellvit/maxvittrainvaltest-local.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cankoc/Coursework/cellvit/maxvittrainvaltest-local.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLabel: \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/matplotlib/pyplot.py:2652\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[1;32m   2647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[1;32m   2648\u001b[0m         X, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, aspect\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, interpolation\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2649\u001b[0m         alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, origin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2650\u001b[0m         interpolation_stage\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filternorm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterrad\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m,\n\u001b[1;32m   2651\u001b[0m         resample\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2652\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mimshow(\n\u001b[1;32m   2653\u001b[0m         X, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm, aspect\u001b[39m=\u001b[39;49maspect,\n\u001b[1;32m   2654\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation, alpha\u001b[39m=\u001b[39;49malpha, vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[1;32m   2655\u001b[0m         vmax\u001b[39m=\u001b[39;49mvmax, origin\u001b[39m=\u001b[39;49morigin, extent\u001b[39m=\u001b[39;49mextent,\n\u001b[1;32m   2656\u001b[0m         interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[1;32m   2657\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm, filterrad\u001b[39m=\u001b[39;49mfilterrad, resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m   2658\u001b[0m         url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[1;32m   2659\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2660\u001b[0m     sci(__ret)\n\u001b[1;32m   2661\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/matplotlib/__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5481\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5474\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5475\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap, norm, interpolation,\n\u001b[1;32m   5476\u001b[0m                       origin, extent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[1;32m   5477\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[1;32m   5478\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5479\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5481\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5482\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5483\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5484\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/matplotlib/image.py:715\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    714\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> 715\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    716\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    718\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    719\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 224, 224) for image data"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMX0lEQVR4nO3bX4il9X3H8fenuxEak0aJk5DuKt2WNbotWnRiJPSPaWizay6WgBdqqFQCixBDLpVCk4I3zUUhBP8siyySm+xNJN0UEyktiQVr4yz4bxVlulKdrOAaQwoGKqvfXsxpc3q+szvPrGfO2cH3CwbmeZ7fOefLMOc9zzzzTKoKSRr3G/MeQNL5xzBIagyDpMYwSGoMg6TGMEhq1g1DksNJXk/y3BmOJ8m3kywneSbJNdMfU9IsDTljeAjYe5bj+4Ddo48DwAPvfSxJ87RuGKrqMeDNsyzZD3ynVj0BXJTkE9MaUNLsbZ/Cc+wAXh3bXhnte21yYZIDrJ5VcOGFF157xRVXTOHlJZ3JsWPH3qiqhY0+bhphyBr71rzPuqoOAYcAFhcXa2lpaQovL+lMkvznuTxuGn+VWAEuHdveCZycwvNKmpNphOEocNvorxPXA7+sqvZrhKStY91fJZJ8F7gBuCTJCvAN4AMAVXUQeAS4EVgGfgXcvlnDSpqNdcNQVbesc7yAr0xtIklz552PkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLI3yYtJlpPcvcbxjyT5QZKnkxxPcvv0R5U0K+uGIck24D5gH7AHuCXJnollXwGer6qrgRuAv09ywZRnlTQjQ84YrgOWq+pEVb0NHAH2T6wp4MNJAnwIeBM4PdVJJc3MkDDsAF4d214Z7Rt3L3AlcBJ4FvhaVb07+URJDiRZSrJ06tSpcxxZ0mYbEoassa8mtj8PPAX8NvCHwL1Jfqs9qOpQVS1W1eLCwsIGR5U0K0PCsAJcOra9k9Uzg3G3Aw/XqmXgZeCK6YwoadaGhOFJYHeSXaMLijcDRyfWvAJ8DiDJx4FPAiemOaik2dm+3oKqOp3kTuBRYBtwuKqOJ7ljdPwgcA/wUJJnWf3V466qemMT55a0idYNA0BVPQI8MrHv4NjnJ4G/mO5okubFOx8lNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVIzKAxJ9iZ5MclykrvPsOaGJE8lOZ7kJ9MdU9IsbV9vQZJtwH3AnwMrwJNJjlbV82NrLgLuB/ZW1StJPrZJ80qagSFnDNcBy1V1oqreBo4A+yfW3Ao8XFWvAFTV69MdU9IsDQnDDuDVse2V0b5xlwMXJ/lxkmNJblvriZIcSLKUZOnUqVPnNrGkTTckDFljX01sbweuBb4AfB74mySXtwdVHaqqxapaXFhY2PCwkmZj3WsMrJ4hXDq2vRM4ucaaN6rqLeCtJI8BVwMvTWVKSTM15IzhSWB3kl1JLgBuBo5OrPkH4I+TbE/yQeDTwAvTHVXSrKx7xlBVp5PcCTwKbAMOV9XxJHeMjh+sqheS/Ah4BngXeLCqntvMwSVtnlRNXi6YjcXFxVpaWprLa0vvF0mOVdXiRh/nnY+SGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJKaQWFIsjfJi0mWk9x9lnWfSvJOkpumN6KkWVs3DEm2AfcB+4A9wC1J9pxh3TeBR6c9pKTZGnLGcB2wXFUnqupt4Aiwf411XwW+B7w+xfkkzcGQMOwAXh3bXhnt+z9JdgBfBA6e7YmSHEiylGTp1KlTG51V0owMCUPW2FcT298C7qqqd872RFV1qKoWq2pxYWFh4IiSZm37gDUrwKVj2zuBkxNrFoEjSQAuAW5Mcrqqvj+NISXN1pAwPAnsTrIL+BlwM3Dr+IKq2vW/nyd5CPhHoyBtXeuGoapOJ7mT1b82bAMOV9XxJHeMjp/1uoKkrWfIGQNV9QjwyMS+NYNQVX/13seSNE/e+SipMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkppBYUiyN8mLSZaT3L3G8S8leWb08XiSq6c/qqRZWTcMSbYB9wH7gD3ALUn2TCx7GfjTqroKuAc4NO1BJc3OkDOG64DlqjpRVW8DR4D94wuq6vGq+sVo8wlg53THlDRLQ8KwA3h1bHtltO9Mvgz8cK0DSQ4kWUqydOrUqeFTSpqpIWHIGvtqzYXJZ1kNw11rHa+qQ1W1WFWLCwsLw6eUNFPbB6xZAS4d294JnJxclOQq4EFgX1X9fDrjSZqHIWcMTwK7k+xKcgFwM3B0fEGSy4CHgb+sqpemP6akWVr3jKGqTie5E3gU2AYcrqrjSe4YHT8IfB34KHB/EoDTVbW4eWNL2kypWvNywaZbXFyspaWluby29H6R5Ni5/JD2zkdJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBknNoDAk2ZvkxSTLSe5e43iSfHt0/Jkk10x/VEmzsm4YkmwD7gP2AXuAW5LsmVi2D9g9+jgAPDDlOSXN0JAzhuuA5ao6UVVvA0eA/RNr9gPfqVVPABcl+cSUZ5U0I9sHrNkBvDq2vQJ8esCaHcBr44uSHGD1jALgv5M8t6Fp5+sS4I15DzHQVpoVtta8W2lWgE+ey4OGhCFr7KtzWENVHQIOASRZqqrFAa9/XthK826lWWFrzbuVZoXVec/lcUN+lVgBLh3b3gmcPIc1kraIIWF4EtidZFeSC4CbgaMTa44Ct43+OnE98Muqem3yiSRtDev+KlFVp5PcCTwKbAMOV9XxJHeMjh8EHgFuBJaBXwG3D3jtQ+c89XxspXm30qywtebdSrPCOc6bqnYpQNL7nHc+SmoMg6Rm08OwlW6nHjDrl0YzPpPk8SRXz2POsXnOOu/Yuk8leSfJTbOcb2KGdWdNckOSp5IcT/KTWc84Mct63wsfSfKDJE+P5h1yXW1TJDmc5PUz3Rd0Tu+xqtq0D1YvVv4H8LvABcDTwJ6JNTcCP2T1XojrgX/fzJne46yfAS4efb5vXrMOnXds3b+weoH4pvN1VuAi4HngstH2x87nry3w18A3R58vAG8CF8xp3j8BrgGeO8PxDb/HNvuMYSvdTr3urFX1eFX9YrT5BKv3a8zLkK8twFeB7wGvz3K4CUNmvRV4uKpeAaiq833eAj6cJMCHWA3D6dmOORqk6rHR65/Jht9jmx2GM90qvdE1s7DROb7MaoXnZd15k+wAvggcnOFcaxnytb0cuDjJj5McS3LbzKbrhsx7L3AlqzfyPQt8rarenc14G7bh99iQW6Lfi6ndTj0Dg+dI8llWw/BHmzrR2Q2Z91vAXVX1zuoPtrkZMut24Frgc8BvAv+W5Imqemmzh1vDkHk/DzwF/Bnwe8A/JfnXqvqvTZ7tXGz4PbbZYdhKt1MPmiPJVcCDwL6q+vmMZlvLkHkXgSOjKFwC3JjkdFV9fyYT/trQ74M3quot4K0kjwFXA/MIw5B5bwf+rlZ/iV9O8jJwBfDT2Yy4IRt/j23yRZHtwAlgF7++iPP7E2u+wP+/MPLTOV3AGTLrZaze3fmZecy40Xkn1j/E/C4+DvnaXgn882jtB4HngD84j+d9APjb0ecfB34GXDLH74ff4cwXHzf8HtvUM4bavNup5zXr14GPAvePfgqfrjn9p93Aec8LQ2atqheS/Ah4BngXeLCq5vJv+QO/tvcADyV5ltU33F1VNZd/x07yXeAG4JIkK8A3gA+Mzbrh95i3REtqvPNRUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUvM/YA1djYGMYyEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(dataloaders['train']))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fUUKdWLEEVjf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_seed(cfg):\n",
        "    random.seed(cfg.random_seed)\n",
        "    np.random.seed(cfg.random_seed)\n",
        "    torch.manual_seed(cfg.random_seed)\n",
        "    if cfg.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(cfg.random_seed)\n",
        "\n",
        "def train_model(cfg, model, dataloaders, criterion, optimizer):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(cfg.num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, cfg.num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'dev']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'dev' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'dev':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Mu4FdLMfHKCL"
      },
      "outputs": [],
      "source": [
        "# model_ft = models.resnet18(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# # Here the size of each output sample is set to 2.\n",
        "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "set_seed(CFG)\n",
        "\n",
        "model_ft = MaxVitClassifier(CFG)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "# print(\"Params to learn:\")\n",
        "\n",
        "# for name,param in model_ft.named_parameters():\n",
        "#     if param.requires_grad == True:\n",
        "#             print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=5e-5, momentum=0.9)\n",
        "optimizer_ft = AdamW(model_ft.parameters(), lr=CFG.learning_rate, eps=CFG.adam_epsilon, weight_decay=CFG.weight_decay)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-HtsnLwtLlKE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/112 [00:00<?, ?it/s]"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        }
      ],
      "source": [
        "model_ft, hist = train_model(CFG, model_ft, dataloaders, criterion, optimizer_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
