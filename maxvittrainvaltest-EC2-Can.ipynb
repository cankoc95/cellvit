{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKbz-q1dYGVp"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install --pre timm\n",
        "!pip install wandb\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tO7DjSN6YDov"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.pyplot._IonContext at 0x7f1df2ff5ac0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import timm\n",
        "import pandas as pd\n",
        "# from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "from datasets import Dataset\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "import cv2\n",
        "import wandb\n",
        "import uuid\n",
        "import tempfile\n",
        "from datetime import datetime, date\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bj-zSDkzpl7h"
      },
      "outputs": [],
      "source": [
        "CELL_PAINTING_DIR = '/home/ubuntu/src'\n",
        "MODEL_OUTPUT_DIR = '/dev/shm'\n",
        "CACHE_DIR = CELL_PAINTING_DIR + \"/cache\"\n",
        "BROAD_DIR = CELL_PAINTING_DIR + '/data/cpg0019-moshkov-deepprofiler/broad'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3M7YRoHJIrxK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n"
          ]
        }
      ],
      "source": [
        "class_labels_to_int = {\n",
        "    'AKT1_E17K': 0,\n",
        "    'AKT1_WT': 1,\n",
        "    'BRAF_V600E': 2,\n",
        "    'BRAF_WT': 3,\n",
        "    'CDC42_Q61L': 4,\n",
        "    'CDC42_T17N': 5,\n",
        "    'CDC42_WT': 6,\n",
        "    'EMPTY': 7,\n",
        "    'KRAS_G12V': 8,\n",
        "    'KRAS_WT': 9,\n",
        "    'RAF1_L613V': 10,\n",
        "    'RAF1_WT': 11,\n",
        "    'RHOA_Q63L': 12,\n",
        "    'RHOA_WT': 13\n",
        "}\n",
        "print(len(class_labels_to_int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YVqgh9ATWVc"
      },
      "source": [
        "### Prepare train/dev dataset (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F56q2a60T1ZI"
      },
      "outputs": [],
      "source": [
        "# def add_image_paths(row, delim='../../', prefix=BROAD_DIR):\n",
        "#     _, path_suffix = row.Image_Name.split(delim)\n",
        "#     path = prefix + \"/\" + path_suffix\n",
        "#     return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "On2y_qoRKC4j"
      },
      "outputs": [],
      "source": [
        "# from data_fetcher import DataFetcher\n",
        "# c037_14k_dataset = pd.read_parquet(CACHE_DIR + \"/c037_14k_metadata.parquet\", engine=\"pyarrow\")\n",
        "# print(c037_14k_dataset.shape)\n",
        "# c037_14k_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v3kjpBM2HmHb"
      },
      "outputs": [],
      "source": [
        "# c037_14k_dataset['Path'] = c037_14k_dataset.apply(lambda x: add_image_paths(x), axis=1)\n",
        "# c037_14k_dataset['Labels'] = c037_14k_dataset[\"Treatment\"].replace(\n",
        "#           to_replace=class_labels_to_int)\n",
        "# print(c037_14k_dataset.shape)\n",
        "# c037_14k_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-vsdbxR7Hs5K"
      },
      "outputs": [],
      "source": [
        "# c037_14k_dataset_clean = DataFetcher.clean_data(c037_14k_dataset)\n",
        "# c037_14k_dataset_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M7ZeNAX0UQQV"
      },
      "outputs": [],
      "source": [
        "# DataFetcher.create_train_dev_split(c037_14k_dataset_clean, CACHE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bsmB1TG4UNsF"
      },
      "outputs": [],
      "source": [
        "# # Add channel information to each train and dev dataset\n",
        "\n",
        "# for dataset_t in [\"train\", \"dev\"]:\n",
        "#   dataset_file = CACHE_DIR + f\"/{dataset_t}/data.parquet\"\n",
        "#   dataset_df = pd.read_parquet(dataset_file, engine=\"pyarrow\")\n",
        "#   dataset_df = DataFetcher.repeat_channels(dataset_df)\n",
        "#   dataset_df = dataset_df.drop(columns=['__index_level_0__'])\n",
        "#   dataset_df.to_parquet(dataset_file, engine=\"pyarrow\")\n",
        "#   print(f\"Added channels to {dataset_file}, shape is: {dataset_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timm.list_models(\"*maxvit*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vAD6_OayJhsT"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "  data_dir = CACHE_DIR\n",
        "  debug = False\n",
        "  n_gpu = 1\n",
        "  # device = \"cpu\" # ['cpu', 'mps']\n",
        "  img_size = 224\n",
        "  ### total # of classes in this dataset\n",
        "  num_classes = len(class_labels_to_int)\n",
        "  ### model\n",
        "  model_name = 'maxvit_large_tf_224'\n",
        "  checkpoint = 'maxvit_large_tf_224'\n",
        "  pretrained=True\n",
        "  batch_size = 16\n",
        "  num_epochs = 30\n",
        "\n",
        "  ### set only one to True\n",
        "  save_best_loss = False\n",
        "  save_best_accuracy = True\n",
        "\n",
        "  optimizer = 'adamw' # [\"rmsprop\", \"adam\"]\n",
        "  learning_rate = 5e-5\n",
        "  adam_epsilon = 1e-6\n",
        "  weight_decay = 0.1 # for adamw\n",
        "  l2_penalty = 0.01 # for RMSprop\n",
        "  rms_momentum = 0 # for RMSprop\n",
        "\n",
        "  ### learning rate scheduler (LRS)\n",
        "  scheduler = 'ReduceLROnPlateau' # []\n",
        "  # scheduler = 'CosineAnnealingLR'\n",
        "  plateau_factor = 0.5\n",
        "  plateau_patience = 3\n",
        "  cosine_T_max = 4\n",
        "  cosine_eta_min = 1e-8\n",
        "  verbose = True\n",
        "\n",
        "  ### train and validation DataLoaders\n",
        "  shuffle = True\n",
        "\n",
        "  random_seed = 42\n",
        "\n",
        "  output_dir = MODEL_OUTPUT_DIR + '/' + str(date.today())\n",
        "  checkpoint_last = output_dir + '/' + model_name + '/checkpoint-last'\n",
        "  checkpoint_best = output_dir + '/' + model_name + '/checkpoint-best'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OCoVXjIL-lO7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcankoc\u001b[0m (\u001b[33mcellvit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/tmp/tmp4n32gsko/wandb/run-20230319_233807-d43c03aa80cd4cc4a14cc056811fdaa1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cellvit/Can-c037_14k--cellvit-maxvit_large_tf_224/runs/d43c03aa80cd4cc4a14cc056811fdaa1' target=\"_blank\">d43c03aa80cd4cc4a14cc056811fdaa1</a></strong> to <a href='https://wandb.ai/cellvit/Can-c037_14k--cellvit-maxvit_large_tf_224' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cellvit/Can-c037_14k--cellvit-maxvit_large_tf_224' target=\"_blank\">https://wandb.ai/cellvit/Can-c037_14k--cellvit-maxvit_large_tf_224</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cellvit/Can-c037_14k--cellvit-maxvit_large_tf_224/runs/d43c03aa80cd4cc4a14cc056811fdaa1' target=\"_blank\">https://wandb.ai/cellvit/Can-c037_14k--cellvit-maxvit_large_tf_224/runs/d43c03aa80cd4cc4a14cc056811fdaa1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "os.environ['WANDB_API_KEY']='808606b1ec54e09c37c9c19ea6bb8d5b8a679987'\n",
        "\n",
        "class WandBLogger(object):\n",
        "    def __init__(self, variant, project, prefix=''):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        variant: dictionary of hyperparameters\n",
        "        project: name of project\n",
        "      \"\"\"\n",
        "      log_dir = tempfile.mkdtemp()\n",
        "      if prefix != '':\n",
        "          project = '{}--{}'.format(prefix, project)\n",
        "\n",
        "      wandb.init(\n",
        "          config=variant,\n",
        "          project=project,\n",
        "          dir=log_dir,\n",
        "          id=uuid.uuid4().hex,\n",
        "      )\n",
        "\n",
        "    def log(self, *args, **kwargs):\n",
        "      wandb.log(*args, **kwargs)\n",
        "\n",
        "wblogger = WandBLogger(\n",
        "    variant={\n",
        "      'initial_learning_rate': CFG.learning_rate,\n",
        "      'adam_epsilon': CFG.adam_epsilon,\n",
        "      'num_epochs': CFG.num_epochs,\n",
        "      'batch_size': CFG.batch_size\n",
        "    },\n",
        "    project=f'cellvit-{CFG.model_name}',\n",
        "    prefix='Can-c037_14k'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riwos9s8Frbj"
      },
      "source": [
        "### Create a custom pytorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0Y1PVZk6X2dO"
      },
      "outputs": [],
      "source": [
        "from maxvit_dataset import MaxVitDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96QFK1BfF3Ro"
      },
      "source": [
        "### Check to see if custom Dataset is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfvWag_GogEB"
      },
      "outputs": [],
      "source": [
        "# training_data = MaxVitDataset(CFG, \"train\")\n",
        "# dev_data = MaxVitDataset(CFG, \"dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLuAKfJRKrGr"
      },
      "outputs": [],
      "source": [
        "# print(\"Training and dev data sizes\")\n",
        "# print(len(training_data))\n",
        "# print(len(dev_data))\n",
        "# print(\"Training and dev data at idx\")\n",
        "# print(training_data[0][0].shape)\n",
        "# print(training_data[0][0].dtype)\n",
        "# print(training_data[0][0])\n",
        "# print(training_data[0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x34kalKxKg5L"
      },
      "source": [
        "### Inspect a subset of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytl8lilzBql2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "# 1. Take in a Dataset as well as a list of class names\n",
        "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "    \n",
        "    # 2. Adjust display if n too high\n",
        "    if n > 10:\n",
        "        n = 10\n",
        "        display_shape = False\n",
        "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "    \n",
        "    # 3. Set random seed\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 4. Get random sample indexes\n",
        "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "    # 5. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 6. Loop through samples and display random samples \n",
        "    for i, targ_sample in enumerate(random_samples_idx):\n",
        "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
        "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "        # Plot adjusted samples\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(targ_image_adjust)\n",
        "        plt.axis(\"off\")\n",
        "        title = f\"class: {targ_label}\"\n",
        "        if display_shape:\n",
        "            title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUBCsvD0DgSj"
      },
      "outputs": [],
      "source": [
        "# display_random_images(training_data, n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Ve1GWlZ1dj"
      },
      "source": [
        "### Fine Tuning With Timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8v-t430TD61V"
      },
      "outputs": [],
      "source": [
        "class MaxVitClassifier(nn.Module):\n",
        "    def __init__(self, cfg, checkpoint=None):\n",
        "        super().__init__()\n",
        "        self.model_name = cfg.model_name\n",
        "        self.model = timm.create_model(cfg.model_name, \n",
        "                                       pretrained=cfg.pretrained, \n",
        "                                       num_classes=cfg.num_classes)\n",
        "        # n_features = self.model.head.in_features\n",
        "        # self.model.head = nn.Linear(n_features, num_classes)\n",
        "        # self.model.fc = nn.Linear(n_features, num_classes)\n",
        "        if checkpoint:\n",
        "          self.model.load_state_dict(torch.load(checkpoint), strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "    \n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in self.model.head.parameters():\n",
        "            param.requires_grad = True\n",
        "    \n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Sx2gF_qeEaga"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset sizes: {'train': 56000, 'dev': 14000}\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'dev': transforms.Compose([\n",
        "        transforms.CenterCrop(CFG.img_size),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: MaxVitDataset(CFG, split=x,\n",
        "                                   transform=data_transforms[x])\n",
        "                  for x in ['train', 'dev']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
        "                                              batch_size=CFG.batch_size,\n",
        "                                              num_workers=20,\n",
        "                                              shuffle=True)\n",
        "              for x in ['train', 'dev']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'dev']}\n",
        "# class_names = image_datasets['train'].classes\n",
        "print(f\"Dataset sizes: {dataset_sizes}\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else CFG.device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fUUKdWLEEVjf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_seed(cfg):\n",
        "    random.seed(cfg.random_seed)\n",
        "    np.random.seed(cfg.random_seed)\n",
        "    torch.manual_seed(cfg.random_seed)\n",
        "    if cfg.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(cfg.random_seed)\n",
        "\n",
        "def train_model(cfg, model, dataloaders, criterion, optimizer, scheduler):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    last_checkpoint_path = CFG.checkpoint_last\n",
        "    # last_scheduler_path = os.path.join(last_checkpoint_path, 'scheduler.pt')\n",
        "    # last_optimizer_path = os.path.join(last_checkpoint_path, 'optimizer.pt')\n",
        "    best_checkpoint_path = CFG.checkpoint_best\n",
        "    # best_scheduler_path = os.path.join(best_checkpoint_path, 'scheduler.pt')\n",
        "    # best_optimizer_path = os.path.join(best_checkpoint_path, 'optimizer.pt')\n",
        "\n",
        "    for epoch in range(cfg.num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, cfg.num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        wblogdict = {}\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'dev']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            wblogdict[f'{phase}/loss'] = np.round(epoch_loss, 4)\n",
        "            wblogdict[f'{phase}/acc'] = np.round(epoch_acc.cpu(), 4)\n",
        "\n",
        "            if phase == \"train\":\n",
        "              wblogdict['train/learning_rate'] = CFG.learning_rate\n",
        "\n",
        "            if not os.path.exists(last_checkpoint_path):\n",
        "                os.makedirs(last_checkpoint_path)\n",
        "            \n",
        "            torch.save(model.state_dict(), last_checkpoint_path + f\"/MaxVitModel_ep{epoch_acc}.pth\")\n",
        "            # torch.save(optimizer.state_dict(), last_optimizer_path)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'dev' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "                if not os.path.exists(best_checkpoint_path):\n",
        "                    os.makedirs(best_checkpoint_path)\n",
        "\n",
        "                torch.save(model.state_dict(), best_checkpoint_path + f\"/MaxVitModel_ep{best_acc}.pth\")\n",
        "                # torch.save(optimizer.state_dict(), best_optimizer_path)\n",
        "  \n",
        "            if phase == 'dev':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "        wblogger.log(wblogdict)\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mu4FdLMfHKCL"
      },
      "outputs": [],
      "source": [
        "# model_ft = models.resnet18(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# # Here the size of each output sample is set to 2.\n",
        "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "set_seed(CFG)\n",
        "\n",
        "# checkpoint = CELL_PAINTING_DIR + '/MaxVitModel_ep0.6236428571428572.pth'\n",
        "model_ft = MaxVitClassifier(CFG)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "# print(\"Params to learn:\")\n",
        "\n",
        "# for name,param in model_ft.named_parameters():\n",
        "#     if param.requires_grad == True:\n",
        "#             print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=5e-5, momentum=0.9)\n",
        "\n",
        "optimizer_ft = AdamW(model_ft.parameters(), lr=CFG.learning_rate, eps=CFG.adam_epsilon, weight_decay=CFG.weight_decay)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=CFG.plateau_factor, patience=CFG.plateau_patience)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-HtsnLwtLlKE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3500/3500 [36:55<00:00,  1.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.7839 Acc: 0.4052\n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: '/dev/2023-03-19'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft, hist \u001b[39m=\u001b[39m train_model(CFG, model_ft, dataloaders, criterion, optimizer_ft, scheduler)\n",
            "Cell \u001b[0;32mIn[15], line 79\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(cfg, model, dataloaders, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     76\u001b[0m   wblogdict[\u001b[39m'\u001b[39m\u001b[39mtrain/learning_rate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m CFG\u001b[39m.\u001b[39mlearning_rate\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(last_checkpoint_path):\n\u001b[0;32m---> 79\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(last_checkpoint_path)\n\u001b[1;32m     81\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), last_checkpoint_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/MaxVitModel_ep\u001b[39m\u001b[39m{\u001b[39;00mepoch_acc\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[39m# torch.save(optimizer.state_dict(), last_optimizer_path)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[39m# deep copy the model\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head \u001b[39mand\u001b[39;00m tail \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         makedirs(head, exist_ok\u001b[39m=\u001b[39;49mexist_ok)\n\u001b[1;32m    216\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
            "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/dev/2023-03-19'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Waiting for W&B process to finish... (success).\n"
          ]
        }
      ],
      "source": [
        "model_ft, hist = train_model(CFG, model_ft, dataloaders, criterion, optimizer_ft, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn2UMID6gR5G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
