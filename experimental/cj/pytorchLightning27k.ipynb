{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "import timm\n",
    "import wandb\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint, DeviceStatsMonitor, ModelSummary\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.fabric import Fabric\n",
    "\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"./saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saved_models'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "  MODEL_NAME = 'maxvit_tiny_tf_224'\n",
    "  START_EPOCH = 0\n",
    "  EPOCHS = 30\n",
    "\n",
    "  TRAIN_BATCH = 32\n",
    "  VAL_BATCH = 32\n",
    "  \n",
    "  PRINT_FREQ = 200\n",
    "  \n",
    "  WORKERS = 4\n",
    "\n",
    "  DATADIR = \"/data/home/ec2-user/broad/training_images/BBBC037/\"\n",
    "  TRAINDIR = DATADIR+\"train_27k\"\n",
    "  VALDIR = DATADIR+\"val_27k\"\n",
    "  TESTDIR = DATADIR+\"test_27k\"\n",
    "\n",
    "  PRETRAINED = False\n",
    "  IMAGE_SIZE = 224\n",
    "  IN_CHANS = 5\n",
    "  NUM_CLASSES = 13 #13 for 27k subset# 45\n",
    "\n",
    "  ### optimizer\n",
    "  LR = 0.01\n",
    "  MOMENTUM = 0.9\n",
    "  ADAM_EPSILON = 1e-6\n",
    "  WEIGHT_DECAY = 1e-8 # for AdamW\n",
    "\n",
    "  RANDOM_SEED = 42\n",
    "\n",
    "  OUTPUT_DIR = '/home/ubuntu' + '/saved_models/' + str(date.today())\n",
    "  CHECKPOINT_LAST = OUTPUT_DIR + '/' + MODEL_NAME + '/checkpoint-last'\n",
    "  CHECKPOINT_BEST = OUTPUT_DIR + '/' + MODEL_NAME + '/checkpoint-best'\n",
    "\n",
    "  WANDB_NOTEBOOK_NAME = str(date.today()) + '_' + MODEL_NAME + '_cjdonahoe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_labels = [\n",
    "#     'AKT1_E17K',\n",
    "#     'AKT1_WT',\n",
    "#     'BRAF_V600E',\n",
    "#     'BRAF_WT',\n",
    "#     'CDC42_Q61L',\n",
    "#     'CDC42_T17N',\n",
    "#     'CDC42_WT',\n",
    "#     'KRAS_G12V',\n",
    "#     'KRAS_WT',\n",
    "#     'RAF1_L613V',\n",
    "#     'RAF1_WT',\n",
    "#     'RHOA_Q63L',\n",
    "#     'RHOA_WT'\n",
    "# ]\n",
    "\n",
    "# for class_label in class_labels:\n",
    "#     for i in [\"train\", \"val\", \"test\"]:\n",
    "#         print(f\"mkdir -p {i}_27k/{class_label}\")\n",
    "\n",
    "# # print one row for every class label and format the output like cp -R test/{class_label}/* ./test_27k/{class_label}/\n",
    "# for class_label in class_labels:\n",
    "#     for i in [\"train\", \"val\", \"test\"]:\n",
    "#         print(f\"cp -R {i}/{class_label}/* {i}_27k/{class_label}/\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcjdonahoe\u001b[0m (\u001b[33mcellvit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230415_215631-i6dtse2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/i6dtse2w' target=\"_blank\">ancient-puddle-77</a></strong> to <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit' target=\"_blank\">https://wandb.ai/cellvit/cjdonahoe--cellvit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/i6dtse2w' target=\"_blank\">https://wandb.ai/cellvit/cjdonahoe--cellvit/runs/i6dtse2w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = pl.loggers.WandbLogger(project='cjdonahoe--cellvit/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(dataset):\n",
    "    ''' Get class weights for a dataset\n",
    "    Args:\n",
    "        dataset: torch.utils.data.Dataset\n",
    "    Returns:\n",
    "        class_weights: torch.FloatTensor\n",
    "    '''\n",
    "    \n",
    "    class_counts = Counter(dataset.targets)\n",
    "    n_classes = len(class_counts.keys())\n",
    "    total_count = len(dataset.targets)\n",
    "    class_weights = list({class_id: total_count/(n_classes * class_counts) for class_id, class_counts in class_counts.items()}.values())\n",
    "    class_weights = torch.FloatTensor(class_weights).cuda()\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitTensorToFiveChannels(object):\n",
    "    \"\"\"Convert images in Pytorch Dataset to Tensors with one channel\n",
    "    for each discrete fluerecent image in a Cell Painting sample.\"\"\"\n",
    "    def __call__(self, img):\n",
    "        # select the first channel since the image is grayscale\n",
    "        img = img[0,:,:]\n",
    "        # split the image into the 6 channels and remove the last channel\n",
    "        img = torch.tensor_split(img,6,dim=1)[:-1]\n",
    "        # concatenate the 5 channels into a single tensor\n",
    "        img = torch.stack(img, dim=0)\n",
    "        return img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.Resize((CFG.IMAGE_SIZE, CFG.IMAGE_SIZE*6)),\n",
    "    transforms.ToTensor(),\n",
    "    SplitTensorToFiveChannels(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.5, 0.5], std=[0.225, 0.225, 0.225, 0.225, 0.225]),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((CFG.IMAGE_SIZE, CFG.IMAGE_SIZE*6)),\n",
    "    transforms.ToTensor(),\n",
    "    SplitTensorToFiveChannels(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5, 0.5, 0.5], std=[0.225, 0.225, 0.225, 0.225, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    CFG.TRAINDIR, transform=transform_train)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    CFG.VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=CFG.TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=CFG.WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=CFG.VAL_BATCH, shuffle=False,\n",
    "        num_workers=CFG.WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Dataset Debug Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize an image from a batch\n",
    "# trainBatch = next(iter(train_loader))\n",
    "\n",
    "# fig = plt.figure(figsize= (15, 15))\n",
    "\n",
    "# for label, minibatch in enumerate(trainBatch):\n",
    "#     print(f'Label: {list(train_dataset.class_to_idx)[label]}') \n",
    "#     print(f'Label index: {label}')\n",
    "#     for i in range(5):\n",
    "#         img = minibatch[0][i].unsqueeze(0)\n",
    "#         img = np.array(img.mul(255), dtype=np.uint8)\n",
    "#         ax = fig.add_subplot(1, 5, i+1)\n",
    "#         ax.imshow(img[0], cmap='gray')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dict(Counter(train_dataset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = get_class_weights(train_dataset)\n",
    "# weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn - MaxViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxViTModule(nn.Module):\n",
    "    def __init__(self, checkpoint=None):\n",
    "        super().__init__()\n",
    "        self.model_name = CFG.MODEL_NAME\n",
    "        self.model = timm.create_model(\n",
    "            CFG.MODEL_NAME,\n",
    "            in_chans=CFG.IN_CHANS,\n",
    "            pretrained=CFG.PRETRAINED, \n",
    "            num_classes=CFG.NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def freeze(self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Lightening Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class LitMaxViT(pl.LightningModule):\n",
    "    def __init__(self, model_name, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = timm.create_model(model_name=CFG.MODEL_NAME, in_chans=CFG.IN_CHANS, pretrained=CFG.PRETRAINED, num_classes=CFG.NUM_CLASSES)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 5, 224, 224), dtype=torch.float32)\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=CFG.NUM_CLASSES)\n",
    "        self.f1 = torchmetrics.classification.MulticlassF1Score(num_classes=CFG.NUM_CLASSES)\n",
    "        # self.multiclassconfusionmatrix = torchmetrics.classification.MulticlassConfusionMatrix(num_classes=CFG.NUM_CLASSES, normalize='true')\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here\n",
    "            # for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer: \"{self.hparams.optimizer_name}\"'\n",
    "\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        acc = self.accuracy(preds, labels)\n",
    "        f1 = self.f1(preds, labels)\n",
    "        # mc_conf_matrix = self.multiclassconfusionmatrix(preds, labels)\n",
    "\n",
    "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1\", f1, on_epoch=True)\n",
    "        # self.log(\"train_mc_conf_matrix\", mc_conf_matrix, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        return loss  # Return tensor to call \".backward\" on\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        acc = self.accuracy(preds, labels)\n",
    "        f1 = self.f1(preds, labels)\n",
    "        # mc_conf_matrix = self.multiclassconfusionmatrix(preds, labels)\n",
    "        # By default logs it per epoch (weighted average over batches)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True)\n",
    "        self.log(\"val_f1\", f1, on_epoch=True)\n",
    "        # self.log(\"val_mc_conf_matrix\", mc_conf_matrix, on_epoch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LitMaxViT(MaxViTModule(CFG))\n",
    "# compiled_model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "\n",
    "def create_model(model_name, model_hparams):\n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name](**model_hparams)\n",
    "    else:\n",
    "        assert False, f'Unknown model name \"{model_name}\". Available models are: {str(model_dict.keys())}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, save_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,  # We log to wandb\n",
    "        profiler=\"simple\", \n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),  # Where to save models\n",
    "        # We run on a single GPU (if possible)\n",
    "        # accelerator=\"auto\",\n",
    "        # devices=-1,\n",
    "        # How many epochs to train for if no patience is set\n",
    "        max_epochs=CFG.EPOCHS,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                save_weights_only=True, mode=\"max\", monitor=\"val_acc\"\n",
    "            ),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "            ModelSummary(max_depth=1),\n",
    "        ],  # Log learning rate every epoch\n",
    "    )  # In case your notebook crashes due to the progress bar, consider increasing the refresh rate\n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = LitMaxViT.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducable\n",
    "        model = LitMaxViT(model_name=model_name, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = LitMaxViT.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )  # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, dataloaders=val_loader, verbose=False)\n",
    "    # test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    result = {\"val\": val_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params | In sizes         | Out sizes\n",
      "----------------------------------------------------------------------------------\n",
      "0 | model       | MaxxVit            | 30.4 M | [1, 5, 224, 224] | [1, 13]  \n",
      "1 | loss_module | CrossEntropyLoss   | 0      | ?                | ?        \n",
      "2 | accuracy    | MulticlassAccuracy | 0      | ?                | ?        \n",
      "3 | f1          | MulticlassF1Score  | 0      | ?                | ?        \n",
      "----------------------------------------------------------------------------------\n",
      "30.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.4 M    Total params\n",
      "121.645   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1826c5b6933443a0a93d640160eb3df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64f6ca8179c428f850701d5dc8b0808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d988ed3504db49d0a1d92878a14c6a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a68a5c1d6b74b10aa162c7765d91e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "No `test_step()` method defined to run `Trainer.test`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[39m.\u001b[39mset_float32_matmul_precision(\u001b[39m'\u001b[39m\u001b[39mhigh\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m model_dict[\u001b[39m\"\u001b[39m\u001b[39mMaxViT\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MaxViTModule\n\u001b[0;32m----> 4\u001b[0m maxvit_model, maxvit_results \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m      5\u001b[0m     model_name\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mMODEL_NAME,\n\u001b[1;32m      6\u001b[0m     \u001b[39m# model_hparams={\"num_classes\": CFG.NUM_CLASSES},\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m     optimizer_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAdam\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     optimizer_hparams\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m: CFG\u001b[39m.\u001b[39;49mLR, \u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m: CFG\u001b[39m.\u001b[39;49mWEIGHT_DECAY},\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[21], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model_name, save_name, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     model \u001b[39m=\u001b[39m LitMaxViT\u001b[39m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m     42\u001b[0m         trainer\u001b[39m.\u001b[39mcheckpoint_callback\u001b[39m.\u001b[39mbest_model_path\n\u001b[1;32m     43\u001b[0m     )  \u001b[39m# Load best checkpoint after training\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# Test best model on validation and test set\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m val_result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtest(model, dataloaders\u001b[39m=\u001b[39;49mval_loader, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     47\u001b[0m \u001b[39m# test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m result \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m: val_result[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_acc\u001b[39m\u001b[39m\"\u001b[39m]}\n",
      "File \u001b[0;32m/opt/conda/envs/torch/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:706\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    704\u001b[0m     model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    705\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 706\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    707\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    708\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/torch/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/conda/envs/torch/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:749\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(model, test_dataloaders\u001b[39m=\u001b[39mdataloaders, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[1;32m    746\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    747\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    748\u001b[0m )\n\u001b[0;32m--> 749\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    750\u001b[0m \u001b[39m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    751\u001b[0m results \u001b[39m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m/opt/conda/envs/torch/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:883\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_callbacks()\n\u001b[1;32m    881\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_logging_functions()\n\u001b[0;32m--> 883\u001b[0m _verify_loop_configurations(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    885\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m    886\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: preparing data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/torch/lib/python3.9/site-packages/lightning/pytorch/trainer/configuration_validator.py:44\u001b[0m, in \u001b[0;36m_verify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     42\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39melif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mTESTING:\n\u001b[0;32m---> 44\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     45\u001b[0m \u001b[39melif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mPREDICTING:\n\u001b[1;32m     46\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/torch/lib/python3.9/site-packages/lightning/pytorch/trainer/configuration_validator.py:108\u001b[0m, in \u001b[0;36m__verify_eval_loop_configuration\u001b[0;34m(model, stage)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_step:\n\u001b[1;32m    107\u001b[0m     trainer_method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalidate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m stage \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m stage\n\u001b[0;32m--> 108\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo `\u001b[39m\u001b[39m{\u001b[39;00mstep_name\u001b[39m}\u001b[39;00m\u001b[39m()` method defined to run `Trainer.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_method\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[39m# check legacy hooks are not present\u001b[39;00m\n\u001b[1;32m    111\u001b[0m epoch_end_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalidation_epoch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m stage \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtest_epoch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: No `test_step()` method defined to run `Trainer.test`."
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "model_dict[\"MaxViT\"] = MaxViTModule\n",
    "\n",
    "maxvit_model, maxvit_results = train_model(\n",
    "    model_name=CFG.MODEL_NAME,\n",
    "    # model_hparams={\"num_classes\": CFG.NUM_CLASSES},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": CFG.LR, \"weight_decay\": CFG.WEIGHT_DECAY},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
