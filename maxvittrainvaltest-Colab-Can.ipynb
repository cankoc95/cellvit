{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKbz-q1dYGVp"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install --pre timm\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO7DjSN6YDov"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import timm\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import Adam, AdamW\n",
        "\n",
        "from datasets import Dataset\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import copy\n",
        "import cv2\n",
        "import wandb\n",
        "import uuid\n",
        "import tempfile\n",
        "from datetime import datetime, date\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kIfV_hmpaZ5"
      },
      "outputs": [],
      "source": [
        "!git clone https://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@github.com/cankoc95/cellvit.git\n",
        "!cd cellvit; git checkout can/maxvittraining; cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV4azyULWNjf"
      },
      "outputs": [],
      "source": [
        "!export PYTHONPATH=/content/cellvit:$PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj-zSDkzpl7h"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MYDRIVE_DIR = '/content/drive/MyDrive'\n",
        "CELL_PAINTING_DIR = MYDRIVE_DIR + '/210-capstone-cell-painting'\n",
        "CACHE_DIR = CELL_PAINTING_DIR + \"/datasets/cache\"\n",
        "BROAD_DIR = MYDRIVE_DIR + '/210-capstone-cell-painting/datasets/cpg0019-moshkov-deepprofiler/broad'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M7YRoHJIrxK"
      },
      "outputs": [],
      "source": [
        "class_labels_to_int = {\n",
        "    'AKT1_E17K': 0,\n",
        "    'AKT1_WT': 1,\n",
        "    'BRAF_V600E': 2,\n",
        "    'BRAF_WT': 3,\n",
        "    'CDC42_Q61L': 4,\n",
        "    'CDC42_T17N': 5,\n",
        "    'CDC42_WT': 6,\n",
        "    'EMPTY': 7,\n",
        "    'KRAS_G12V': 8,\n",
        "    'KRAS_WT': 9,\n",
        "    'RAF1_L613V': 10,\n",
        "    'RAF1_WT': 11,\n",
        "    'RHOA_Q63L': 12,\n",
        "    'RHOA_WT': 13\n",
        "}\n",
        "print(len(class_labels_to_int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YVqgh9ATWVc"
      },
      "source": [
        "### Prepare train/dev dataset (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F56q2a60T1ZI"
      },
      "outputs": [],
      "source": [
        "# def add_image_paths(row, delim='../../', prefix=BROAD_DIR):\n",
        "#     _, path_suffix = row.Image_Name.split(delim)\n",
        "#     path = prefix + \"/\" + path_suffix\n",
        "#     return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On2y_qoRKC4j"
      },
      "outputs": [],
      "source": [
        "# from cellvit.data_fetcher import DataFetcher\n",
        "# c037_14k_dataset = pd.read_parquet(CACHE_DIR + \"/c037_14k_metadata.parquet\", engine=\"pyarrow\")\n",
        "# print(c037_14k_dataset.shape)\n",
        "# c037_14k_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3kjpBM2HmHb"
      },
      "outputs": [],
      "source": [
        "# c037_14k_dataset['Path'] = c037_14k_dataset.apply(lambda x: add_image_paths(x), axis=1)\n",
        "# c037_14k_dataset['Labels'] = c037_14k_dataset[\"Treatment\"].replace(\n",
        "#           to_replace=class_labels_to_int)\n",
        "# print(c037_14k_dataset.shape)\n",
        "# c037_14k_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vsdbxR7Hs5K"
      },
      "outputs": [],
      "source": [
        "# c037_14k_dataset_clean = DataFetcher.clean_data(c037_14k_dataset)\n",
        "# c037_14k_dataset_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7ZeNAX0UQQV"
      },
      "outputs": [],
      "source": [
        "# DataFetcher.create_train_dev_split(c037_14k_dataset_clean, CACHE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsmB1TG4UNsF"
      },
      "outputs": [],
      "source": [
        "# # Add channel information to each train and dev dataset\n",
        "\n",
        "# for dataset_t in [\"train\", \"dev\"]:\n",
        "#   dataset_file = CACHE_DIR + f\"/{dataset_t}/data.parquet\"\n",
        "#   dataset_df = pd.read_parquet(dataset_file, engine=\"pyarrow\")\n",
        "#   dataset_df = DataFetcher.repeat_channels(dataset_df)\n",
        "#   dataset_df = dataset_df.drop(columns=['__index_level_0__'])\n",
        "#   dataset_df.to_parquet(dataset_file, engine=\"pyarrow\")\n",
        "#   print(f\"Added channels to {dataset_file}, shape is: {dataset_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAD6_OayJhsT"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "  data_dir = CELL_PAINTING_DIR + \"/datasets/cache\"\n",
        "  debug = False\n",
        "  n_gpu = 1\n",
        "  # device = \"cpu\" # ['cpu', 'mps']\n",
        "  img_size = 224\n",
        "  ### total # of classes in this dataset\n",
        "  num_classes = len(class_labels_to_int)\n",
        "  ### model\n",
        "  model_name = 'maxvit_base_tf_224'\n",
        "  checkpoint = 'maxvit_base_tf_224'\n",
        "  pretrained=True\n",
        "  batch_size = 32\n",
        "  num_epochs = 20\n",
        "\n",
        "  ### set only one to True\n",
        "  save_best_loss = False\n",
        "  save_best_accuracy = True\n",
        "\n",
        "  optimizer = 'adamw' # [\"rmsprop\", \"adam\"]\n",
        "  learning_rate = 5e-5\n",
        "  adam_epsilon = 1e-6\n",
        "  weight_decay = 0.1 # for adamw\n",
        "  l2_penalty = 0.01 # for RMSprop\n",
        "  rms_momentum = 0 # for RMSprop\n",
        "\n",
        "  ### learning rate scheduler (LRS)\n",
        "  scheduler = 'ReduceLROnPlateau' # []\n",
        "  # scheduler = 'CosineAnnealingLR'\n",
        "  plateau_factor = 0.5\n",
        "  plateau_patience = 3\n",
        "  cosine_T_max = 4\n",
        "  cosine_eta_min = 1e-8\n",
        "  verbose = True\n",
        "\n",
        "  ### train and validation DataLoaders\n",
        "  shuffle = True\n",
        "\n",
        "  random_seed = 42\n",
        "\n",
        "  output_dir = CELL_PAINTING_DIR + '/saved_models_Can/' + str(date.today())\n",
        "  checkpoint_last = output_dir + '/' + model_name + '/checkpoint-last'\n",
        "  checkpoint_best = output_dir + '/' + model_name + '/checkpoint-best'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCoVXjIL-lO7"
      },
      "outputs": [],
      "source": [
        "os.environ['WANDB_API_KEY']='808606b1ec54e09c37c9c19ea6bb8d5b8a679987'\n",
        "\n",
        "class WandBLogger(object):\n",
        "    def __init__(self, variant, project, prefix=''):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        variant: dictionary of hyperparameters\n",
        "        project: name of project\n",
        "      \"\"\"\n",
        "      log_dir = tempfile.mkdtemp()\n",
        "      if prefix != '':\n",
        "          project = '{}--{}'.format(prefix, project)\n",
        "\n",
        "      wandb.init(\n",
        "          config=variant,\n",
        "          project=project,\n",
        "          dir=log_dir,\n",
        "          id=uuid.uuid4().hex,\n",
        "      )\n",
        "\n",
        "    def log(self, *args, **kwargs):\n",
        "      wandb.log(*args, **kwargs)\n",
        "\n",
        "wblogger = WandBLogger(\n",
        "    variant={\n",
        "      'initial_learning_rate': CFG.learning_rate,\n",
        "      'adam_epsilon': CFG.adam_epsilon,\n",
        "      'num_epochs': CFG.num_epochs,\n",
        "      'batch_size': CFG.batch_size\n",
        "    },\n",
        "    project=f'cellvit-{CFG.model_name}',\n",
        "    prefix='c037_14k'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riwos9s8Frbj"
      },
      "source": [
        "### Create a custom pytorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y1PVZk6X2dO"
      },
      "outputs": [],
      "source": [
        "from cellvit.maxvit_dataset import MaxVitDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96QFK1BfF3Ro"
      },
      "source": [
        "### Check to see if custom Dataset is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfvWag_GogEB"
      },
      "outputs": [],
      "source": [
        "# training_data = MaxVitDataset(CFG, \"train\")\n",
        "# dev_data = MaxVitDataset(CFG, \"dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLuAKfJRKrGr"
      },
      "outputs": [],
      "source": [
        "# print(\"Training and dev data sizes\")\n",
        "# print(len(training_data))\n",
        "# print(len(dev_data))\n",
        "# print(\"Training and dev data at idx\")\n",
        "# print(training_data[0][0].shape)\n",
        "# print(training_data[0][0].dtype)\n",
        "# print(training_data[0][0])\n",
        "# print(training_data[0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x34kalKxKg5L"
      },
      "source": [
        "### Inspect a subset of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytl8lilzBql2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "# 1. Take in a Dataset as well as a list of class names\n",
        "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "    \n",
        "    # 2. Adjust display if n too high\n",
        "    if n > 10:\n",
        "        n = 10\n",
        "        display_shape = False\n",
        "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "    \n",
        "    # 3. Set random seed\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 4. Get random sample indexes\n",
        "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "    # 5. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 6. Loop through samples and display random samples \n",
        "    for i, targ_sample in enumerate(random_samples_idx):\n",
        "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [color_channels, height, width]\n",
        "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "        # Plot adjusted samples\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(targ_image_adjust)\n",
        "        plt.axis(\"off\")\n",
        "        title = f\"class: {targ_label}\"\n",
        "        if display_shape:\n",
        "            title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUBCsvD0DgSj"
      },
      "outputs": [],
      "source": [
        "# display_random_images(training_data, n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Ve1GWlZ1dj"
      },
      "source": [
        "### Fine Tuning With Timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v-t430TD61V"
      },
      "outputs": [],
      "source": [
        "class MaxVitClassifier(nn.Module):\n",
        "    def __init__(self, cfg, checkpoint=None):\n",
        "        super().__init__()\n",
        "        self.model_name = cfg.model_name\n",
        "        self.model = timm.create_model(cfg.model_name, \n",
        "                                       pretrained=cfg.pretrained, \n",
        "                                       num_classes=cfg.num_classes)\n",
        "        # n_features = self.model.head.in_features\n",
        "        # self.model.head = nn.Linear(n_features, num_classes)\n",
        "        # self.model.fc = nn.Linear(n_features, num_classes)\n",
        "        if checkpoint:\n",
        "          self.model.load_state_dict(torch.load(checkpoint), strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "    \n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in self.model.head.parameters():\n",
        "            param.requires_grad = True\n",
        "    \n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx2gF_qeEaga"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'dev': transforms.Compose([\n",
        "        transforms.CenterCrop(CFG.img_size),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: MaxVitDataset(CFG, split=x,\n",
        "                                   transform=data_transforms[x])\n",
        "                  for x in ['train', 'dev']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
        "                                              batch_size=CFG.batch_size,\n",
        "                                              num_workers=20,\n",
        "                                              shuffle=True)\n",
        "              for x in ['train', 'dev']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'dev']}\n",
        "# class_names = image_datasets['train'].classes\n",
        "print(f\"Dataset sizes: {dataset_sizes}\")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else CFG.device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUUKdWLEEVjf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def set_seed(cfg):\n",
        "    random.seed(cfg.random_seed)\n",
        "    np.random.seed(cfg.random_seed)\n",
        "    torch.manual_seed(cfg.random_seed)\n",
        "    if cfg.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(cfg.random_seed)\n",
        "\n",
        "def train_model(cfg, model, dataloaders, criterion, optimizer):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    last_checkpoint_path = CFG.checkpoint_last\n",
        "    last_scheduler_path = os.path.join(last_checkpoint_path, 'scheduler.pt')\n",
        "    last_optimizer_path = os.path.join(last_checkpoint_path, 'optimizer.pt')\n",
        "    best_checkpoint_path = CFG.checkpoint_best\n",
        "    best_scheduler_path = os.path.join(best_checkpoint_path, 'scheduler.pt')\n",
        "    best_optimizer_path = os.path.join(best_checkpoint_path, 'optimizer.pt')\n",
        "\n",
        "    for epoch in range(cfg.num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, cfg.num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        wblogdict = {}\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'dev']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            wblogdict[f'{phase}/loss'] = np.round(epoch_loss, 4)\n",
        "            wblogdict[f'{phase}/acc'] = np.round(epoch_acc.cpu(), 3)\n",
        "\n",
        "            if phase == \"train\":\n",
        "              wblogdict['train/learning_rate'] = CFG.learning_rate\n",
        "\n",
        "            if not os.path.exists(last_checkpoint_path):\n",
        "                os.makedirs(last_checkpoint_path)\n",
        "            \n",
        "            torch.save(model.state_dict(), last_checkpoint_path + f\"/MaxVitModel_ep{epoch_acc}.pth\")\n",
        "            torch.save(optimizer.state_dict(), last_optimizer_path)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'dev' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "                if not os.path.exists(best_checkpoint_path):\n",
        "                    os.makedirs(best_checkpoint_path)\n",
        "\n",
        "                torch.save(model.state_dict(), best_checkpoint_path + f\"/MaxVitModel_ep{best_acc}.pth\")\n",
        "                torch.save(optimizer.state_dict(), best_optimizer_path)\n",
        "  \n",
        "            if phase == 'dev':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        wblogger.log(wblogdict)\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu4FdLMfHKCL"
      },
      "outputs": [],
      "source": [
        "# model_ft = models.resnet18(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# # Here the size of each output sample is set to 2.\n",
        "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "set_seed(CFG)\n",
        "\n",
        "# checkpoint = CELL_PAINTING_DIR + '/saved_models_Can/maxvit_base_tf_224/checkpoint-best/MaxVitModel_ep0.8356428571428572.pth'\n",
        "model_ft = MaxVitClassifier(CFG)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "# print(\"Params to learn:\")\n",
        "\n",
        "# for name,param in model_ft.named_parameters():\n",
        "#     if param.requires_grad == True:\n",
        "#             print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=5e-5, momentum=0.9)\n",
        "optimizer_ft = AdamW(model_ft.parameters(), lr=CFG.learning_rate, eps=CFG.adam_epsilon, weight_decay=CFG.weight_decay)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HtsnLwtLlKE"
      },
      "outputs": [],
      "source": [
        "model_ft, hist = train_model(CFG, model_ft, dataloaders, criterion, optimizer_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn2UMID6gR5G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
